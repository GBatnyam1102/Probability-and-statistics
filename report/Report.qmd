---
title: "–¢–µ–∫—Å—Ç—ç–Ω –º—ç–¥—ç—ç–ª–ª–∏–π–Ω —Å—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª–∏–π–≥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∞—Ä–≥–∞–∞—Ä –∞–Ω–≥–∏–ª–∞—Ö –Ω—å: –ì—ç–Ω—ç–Ω –ë–∞–π–µ—Å –±–æ–ª–æ–Ω –õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å–∏–π–Ω —Ö–∞—Ä—å—Ü—É—É–ª—Å–∞–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç"
subtitle: "–ú–∞—à–∏–Ω —Å—É—Ä–≥–∞–ª—Ç—ã–Ω —Ç”©—Å”©–ª"
abstract: –≠–Ω—ç—Ö“Ø“Ø —Ç”©—Å–ª–∏–π–Ω —Ö“Ø—Ä—ç—ç–Ω–¥ –Ω–∏–π–≥–º–∏–π–Ω —Å“Ø–ª–∂—ç—ç–Ω–∏–π "Sentiment140" ”©–≥”©–≥–¥”©–ª –¥—ç—ç—Ä —Ö—è–Ω–∞–ª—Ç—Ç–∞–π –º–∞—à–∏–Ω —Å—É—Ä–≥–∞–ª—Ç—ã–Ω (Supervised Learning) –∞—Ä–≥—É—É–¥—ã–≥ –∞—à–∏–≥–ª–∞–Ω —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Å—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª–∏–π–≥ —ç–µ—Ä—ç–≥ –±–æ–ª–æ–Ω —Å”©—Ä”©–≥ –≥—ç–∂ –∞–Ω–≥–∏–ª–∞–≤. –ë–∏–¥ ”©–≥”©–≥–¥–ª–∏–π–Ω —Ç“Ø“Ø–≤—ç—Ä –¥—ç—ç—Ä –ì—ç–Ω—ç–Ω –ë–∞–π–µ—Å—ã–Ω (Naive Bayes) –∞—Ä–≥–∞–∞—Ä –ø–æ—Å—Ç–µ—Ä–∏–æ—Ä –º–∞–≥–∞–¥–ª–∞–ª—ã–≥ —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö –±–æ–ª–æ–Ω –õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å–∏–π–Ω (Logistic Regression) –ª–æ–∂–∏—Ç –∑–∞–≥–≤–∞—Ä—ã–≥ —Ö–∞—Ä—å—Ü—É—É–ª–∞–Ω —Ç—É—Ä—à–∏–≤. –°—É–¥–∞–ª–≥–∞–∞–Ω—ã “Ø—Ä –¥“Ø–Ω–¥ –õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å –∑–∞–≥–≤–∞—Ä –Ω—å 78.5%-–∏–π–Ω –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—Ç–∞–π–≥–∞–∞—Ä —Ç–µ–∫—Å—Ç–∏–π–Ω —É—Ç–≥—ã–≥ –∑”©–≤ —Ç–∞–Ω—å–∂, —Ö–∞—Ä—å—Ü—É—É–ª—Å–∞–Ω –∑–∞–≥–≤–∞—Ä–∞–∞—Å –∏–ª“Ø“Ø –æ–Ω–æ–≤—á—Ç–æ–π “Ø—Ä –¥“Ø–Ω “Ø–∑“Ø“Ø–ª—Å—ç–Ω –±–∞–π–Ω–∞. “Æ—Ä –¥“Ø–Ω–≥ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ –±–∞–π–¥–ª–∞–∞—Ä —à–∏–Ω–∂–ª—ç—Ö –∑–æ—Ä–∏–ª–≥–æ–æ—Ä Streamlit –≤–µ–± —Å–∞–º–±–∞—Ä —Ö”©–≥–∂“Ø“Ø–ª—ç–≤.
author: "–õ.–ê–Ω—É–∂–∏–Ω, –ì.–ë–∞—Ç–Ω—è–º, –≠.–ú—ç–Ω–¥–±–∞—è—Ä, –ë.–•—É–≤—å–∑–∞—è–∞, –ê.–≠—Ä—Ö—ç—Å"
date: 2025-11-29
date-format: "YYYY –æ–Ω—ã M-—Ä —Å–∞—Ä—ã–Ω D"
project:
  execute-dir: project
  preview: false
toc: true
toc-depth: 3
toc-title: –ê–≥—É—É–ª–≥–∞
number-sections: true
format:
  pdf:
    echo: true
    pdf-engine: xelatex
    papersize: a4paper
    geometry:
      - left=2cm
      - right=2cm
      - top=2cm
      - bottom=3cm
    include-in-header:
      - text: |
          \usepackage[english,mongolian]{babel}
          \usepackage{fontspec}
          % “Ø–Ω–¥—Å—ç–Ω —Ç–µ–∫—Å—Ç–∏–π–Ω —à—Ä–∏—Ñ—Ç
          \setmainfont{Times New Roman}
          % –∫–æ–¥ —Ö—ç—Å–≥–∏–π–Ω —à—Ä–∏—Ñ—Ç
          \setmonofont{DejaVu Sans Mono}
          \AddToHook{env/Highlighting/begin}{\footnotesize}
          % “Ø–Ω–¥—Å—ç–Ω –≥–∞—Ä—á–∏–≥
          \usepackage{titling}
          \pretitle{\begin{center}\LARGE\bfseries}
          \posttitle{\par\end{center}\vskip 1em}
          % —Å—ç–¥–≤–∏–π–Ω –∑“Ø–π–ª—á–ª—ç–ª —Ö—ç—Å–≥–∏–π–Ω —à—Ä–∏—Ñ—Ç
          \usepackage{titlesec}
          \titleformat{\section}{\normalfont\Large\bfseries\selectfont}{\thesection}{1em}{}
          \titleformat{\subsection}{\normalfont\large\bfseries\selectfont}{\thesubsection}{1em}{}
          \titleformat{\subsubsection}{\normalfont\normalsize\bfseries\selectfont}{\thesubsubsection}{1em}{}
          % —Å—ç–¥–≤–∏–π–Ω –∂–∞–≥—Å–∞–∞–ª—Ç –¥–æ—Ç–æ—Ä—Ö —à—Ä–∏—Ñ—Ç
          \usepackage{tocloft}
          \renewcommand{\cfttoctitlefont}{\Large\bfseries\fontspec{Times New Roman}}
          \renewcommand{\cftaftertoctitle}{\vskip 1em}
          \renewcommand{\cftsecfont}{\normalfont\selectfont}
          \renewcommand{\cftsecpagefont}{\normalfont\selectfont}
          \renewcommand{\cftsubsecfont}{\normalfont\selectfont}
          \renewcommand{\cftsubsecpagefont}{\normalfont\selectfont}
          \renewcommand{\contentsname}{–ê–≥—É—É–ª–≥–∞}
    latex-max-runs: 3
editor: source
execute:
  echo: false
crossref: 
  fig-title: –ó—É—Ä–∞–≥
  fig-prefix: –ó—É—Ä–∞–≥
  tbl-title: –•“Ø—Å–Ω—ç–≥—Ç
  tbl-prefix: –•“Ø—Å–Ω—ç–≥—Ç
fig-align: center
fig-env: "figure"
fig-height: 4
fig-width: 6
fig-pos: "!ht"
fig-format: pdf
fig-cap-location: top
tbl-cap-location: top
bibliography: references.bib
csl: ieee.csl
citeproc: true
link-citations: true
---

```{python}
#| echo: false
# –î“Ø–≥–Ω—ç–ª—Ç —Ö–∞–¥–≥–∞–ª–∞—Ö –∂–∞–≥—Å–∞–∞–ª—Ç
conclusion = list()
```


# –®–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π –±–∞–≥—Ü—É—É–¥ {-}
–®–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π –±–∞–≥—Ü—É—É–¥—ã–≥ –¥–∞—Ä–∞–∞—Ö –±–∞–π–¥–ª–∞–∞—Ä —É—Ä—å–¥—á–∏–ª–∞–Ω —Å—É—É–ª–≥–∞–Ω–∞.

`pip install streamlit pandas numpy scikit-learn matplotlib seaborn plotly`

# –£–¥–∏—Ä—Ç–≥–∞–ª

–ù–∏–π–≥–º–∏–π–Ω —Å“Ø–ª–∂—ç—ç, —Ç—ç—Ä –¥—É–Ω–¥–∞–∞ Twitter (–æ–¥–æ–æ–≥–∏–π–Ω X) –ø–ª–∞—Ç—Ñ–æ—Ä–º –Ω—å –æ–ª–æ–Ω –Ω–∏–π—Ç–∏–π–Ω —Å–∞–Ω–∞–∞ –±–æ–¥–æ–ª, —Ö–∞–Ω–¥–ª–∞–≥—ã–≥ –∏–ª—ç—Ä—Ö–∏–π–ª—ç—Ö —Ç–æ–º–æ–æ—Ö–æ–Ω —ç—Ö —Å—É—Ä–≤–∞–ª–∂ —é–º. –•—ç—Ä—ç–≥–ª—ç–≥—á–∏–¥ ”©”©—Ä—Å–¥–∏–π–Ω “Ø–∑—ç–ª –±–æ–¥–ª–æ–æ –±–æ–≥–∏–Ω–æ —Ö—ç–º–∂—ç—ç–Ω–∏–π —Ç–µ–∫—Å—Ç –±—É—é—É "–∂–∏—Ä–≥—ç—ç" (tweet) —Ö—ç–ª–±—ç—Ä—ç—ç—Ä –∏–ª—ç—Ä—Ö–∏–π–ª–¥—ç–≥. –≠–¥–≥—ç—ç—Ä –∏—Ö —Ö—ç–º–∂—ç—ç–Ω–∏–π ”©–≥”©–≥–¥”©–ª–¥ –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç —Ö–∏–π—Ö –Ω—å –±–∏–∑–Ω–µ—Å–∏–π–Ω –±–∞–π–≥—É—É–ª–ª–∞–≥–∞ –±–æ–ª–æ–Ω —Å—É–¥–ª–∞–∞—á–¥–∞–¥ —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Å—ç—Ç–≥—ç–ª —Ö–∞–Ω–∞–º–∂–∏–π–≥ “Ø–Ω—ç–ª—ç—Ö—ç–¥ —á—É—Ö–∞–ª –∞—á —Ö–æ–ª–±–æ–≥–¥–æ–ª—Ç–æ–π –±–æ–ª–æ–≤—á —Å–∞—è —Å–∞—è –∂–∏—Ä–≥—ç—ç–≥ —Ö“Ø–Ω–∏–π –æ—Ä–æ–ª—Ü–æ–æ—Ç–æ–π–≥–æ–æ—Ä —É–Ω—à–∏–∂ –∞–Ω–≥–∏–ª–∞—Ö –±–æ–ª–æ–º–∂–≥“Ø–π —é–º.

–ò–π–º–¥ —ç–Ω—ç—Ö“Ø“Ø —Ç”©—Å–ª–∏–π–Ω –∞–∂–ª–∞–∞—Ä –±–∏–¥ –°—Ç—ç–Ω—Ñ–æ—Ä–¥—ã–Ω –∏—Ö —Å—É—Ä–≥—É—É–ª–∏–π–Ω —Å—É–¥–ª–∞–∞—á–¥—ã–Ω –±–æ–ª–æ–≤—Å—Ä—É—É–ª—Å–∞–Ω **Sentiment140** ”©–≥”©–≥–¥–ª–∏–π–Ω —Å–∞–Ω–¥ —Ç—É–ª–≥—É—É—Ä–ª–∞–Ω, —Å—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª–∏–π–≥ –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä —Ç–∞–Ω—å–∂, —ç–µ—Ä—ç–≥ –±–æ–ª–æ–Ω —Å”©—Ä”©–≥ –≥—ç–∂ –∞–Ω–≥–∏–ª–∞—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∑–∞–≥–≤–∞—Ä—ã–≥ —Ö”©–≥–∂“Ø“Ø–ª—ç–≤. –°—É–¥–∞–ª–≥–∞–∞–Ω–¥ **–ì—ç–Ω—ç–Ω –ë–∞–π–µ—Å—ã–Ω –∞–ª–≥–æ—Ä–∏—Ç–º** (Naive Bayes) –±–æ–ª–æ–Ω **–õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å** (Logistic Regression) –≥—ç—Å—ç–Ω —Ö–æ—ë—Ä ”©”©—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∞—Ä–≥—ã–≥ –∞—à–∏–≥–ª–∞–∂, —Ç—ç–¥–≥—ç—ç—Ä–∏–π–Ω “Ø—Ä –¥“Ø–Ω–≥ —Ö–∞—Ä—å—Ü—É—É–ª–∞–Ω —à–∏–Ω–∂–∏–ª–ª—ç—ç.

# ”®–≥”©–≥–¥”©–ª –±–∞ –ë–æ–ª–æ–≤—Å—Ä—É—É–ª–∞–ª—Ç

## ”®–≥”©–≥–¥–ª–∏–π–Ω —ç—Ö —Å—É—Ä–≤–∞–ª–∂ –±–∞ –±“Ø—Ç—ç—Ü

–≠–Ω—ç—Ö“Ø“Ø —Å—É–¥–∞–ª–≥–∞–∞–Ω–¥ –±–∏–¥ Alec Go, Richa Bhayani, Lei Huang –Ω–∞—Ä—ã–Ω (2009) —Ü—É–≥–ª—É—É–ª—Å–∞–Ω **Sentiment140** @sentiment140 ”©–≥”©–≥–¥–ª–∏–π–Ω —Å–∞–Ω–≥ –∞—à–∏–≥–ª–∞–≤. –£–≥ ”©–≥”©–≥–¥–ª–∏–π–Ω —Å–∞–Ω –Ω—å Twitter API –∞—à–∏–≥–ª–∞–Ω —Ü—É–≥–ª—É—É–ª—Å–∞–Ω 1.6 —Å–∞—è –∂–∏—Ä–≥—ç—ç–Ω—ç—ç—Å –±“Ø—Ä–¥—ç–Ω—ç. ”®–≥”©–≥–¥–ª–∏–π–Ω —Ö–∞—è–≥–∂—É—É–ª–∞–ª—Ç (Labeling) –Ω—å "–ó–∞–π–Ω–∞–∞—Å —Ö—è–Ω–∞–ª—Ç—Ç–∞–π —Å—É—Ä–≥–∞–ª—Ç" (Distant Supervision) –∞—Ä–≥–∞–∞—Ä —Ö–∏–π–≥–¥—Å—ç–Ω. –¢–æ–¥—Ä—É—É–ª–±–∞–ª:

* –°—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª –∏–ª—ç—Ä—Ö–∏–π–ª—Å—ç–Ω —Ç—ç–º–¥—ç–≥—Ç `:)` –∞–≥—É—É–ª—Å–∞–Ω –∂–∏—Ä–≥—ç—ç–≥ **"–≠–µ—Ä—ç–≥" (4)**,
* `:( ` —Ç—ç–º–¥—ç–≥—Ç –∞–≥—É—É–ª—Å–∞–Ω –∂–∏—Ä–≥—ç—ç–≥ **"–°”©—Ä”©–≥" (0)** –≥—ç–∂ –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä –∞–Ω–≥–∏–ª—Å–∞–Ω.

–°—É—Ä–≥–∞–ª—Ç—ã–Ω —è–≤—Ü–∞–¥ –∑–∞–≥–≤–∞—Ä –∑”©–≤—Ö”©–Ω —Ç—ç–º–¥—ç–≥—Ç–∏–π–≥ —Ü—ç—ç–∂–ª—ç—Ö—ç—ç—Å —Å—ç—Ä–≥–∏–π–ª–∂, –∂–∏—Ä–≥—ç—ç–Ω–∏–π —Ç–µ–∫—Å—Ç—ç—ç—Å —ç–¥–≥—ç—ç—Ä —Ç—ç–º–¥—ç–≥—Ç“Ø“Ø–¥–∏–π–≥ (emoticons) —É—Å—Ç–≥–∞—Å–∞–Ω –±–∞–π–¥–∞–≥. –ë–∏–¥–Ω–∏–π –∞—à–∏–≥–ª–∞—Å–∞–Ω ”©–≥”©–≥–¥–ª–∏–π–Ω –±“Ø—Ç—ç—Ü @tbl-data-preview —Ö–∞—Ä—É—É–ª—Å–∞–Ω –±–∞–π–¥–∞–ª—Ç–∞–π –±–∞–π–Ω–∞:

```{python}
#| echo: false
#| label: tbl-data-preview
#| tbl-cap: ”®–≥”©–≥–¥–ª–∏–π–Ω –±“Ø—Ç—Ü–∏–π–Ω –∂–∏—à—ç—ç (sample_set.csv)

import pandas as pd
from IPython.display import Markdown

# 1. Read the local file
df_sample = pd.read_csv(
	"sample_set.csv",
	encoding="latin-1",
	header=None, 
	names=["target", "id", "date", "flag", "user", "text"]
)

# 2. Select columns want to show
subset = df_sample[["target", "text"]].sample(n=5, random_state=1).copy()

# 3. Rename columns for the Mongolian Report
subset.columns = ["–ê–Ω–≥–∏–ª–∞–ª (Target)", "–ñ–∏—Ä–≥—ç—ç (Text)"]

# 4. Truncate text
subset["–ñ–∏—Ä–≥—ç—ç (Text)"] = subset["–ñ–∏—Ä–≥—ç—ç (Text)"].astype(str).str.slice(0,70) + "..."

# 5. Print
Markdown(subset.to_markdown(index=False))
```

## ”®–≥”©–≥–¥–ª–∏–π–Ω —Ç“Ø“Ø–≤—ç—Ä–ª—ç–ª—Ç (Sampling)

Sentiment140 ”©–≥”©–≥–¥–ª–∏–π–Ω —Å–∞–Ω –Ω—å –Ω–∏–π—Ç 1.6 —Å–∞—è –º”©—Ä –±“Ø—Ö–∏–π –∏—Ö —Ö—ç–º–∂—ç—ç–Ω–∏–π ”©–≥”©–≥–¥–ª–∏–π–≥ –∞–≥—É—É–ª–¥–∞–≥. –≠–Ω—ç—Ö“Ø“Ø —Ç”©—Å–ª–∏–π–Ω —Ö“Ø—Ä—ç—ç–Ω–¥ —Ç–æ–æ—Ü–æ–æ–ª–ª—ã–Ω –Ω”©”©—Ü –±–æ–ª–æ–Ω —Ö—É–≥–∞—Ü–∞–∞–≥ —Ö—ç–º–Ω—ç—Ö –∑–æ—Ä–∏–ª–≥–æ–æ—Ä –±–∏–¥ "–°–∞–Ω–∞–º—Å–∞—Ä–≥“Ø–π —Ç“Ø“Ø–≤—ç—Ä–ª—ç–ª—Ç" (Simple Random Sampling)-–∏–π–Ω –∞—Ä–≥—ã–≥ –∞—à–∏–≥–ª–∞–≤.

–ë–∏–¥ Python —Ö—ç–ª–Ω–∏–π `sample()` —Ñ—É–Ω–∫—Ü–∏–π–≥ –∞—à–∏–≥–ª–∞–Ω –Ω–∏–π—Ç ”©–≥”©–≥–¥–ª”©”©—Å **50,000** –∂–∏—Ä–≥—ç—ç–≥ —Å–∞–Ω–∞–º—Å–∞—Ä–≥“Ø–π –±–∞–π–¥–ª–∞–∞—Ä —Å–æ–Ω–≥–æ–Ω –∞–≤—á —Å—É—Ä–≥–∞–ª—Ç–∞–¥ –∞—à–∏–≥–ª–∞—Å–∞–Ω. –¢—É—Ä—à–∏–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω –¥–∞—Ö–∏–Ω –¥–∞–≤—Ç–∞–≥–¥–∞—Ö (reproducible) –±–æ–ª–æ–º–∂—Ç–æ–π –±–∞–π—Ö—ã–Ω —Ç—É–ª–¥ `random_state=42` —Ç–æ—Ö–∏—Ä–≥–æ–æ–≥ –∞—à–∏–≥–ª–∞—Å–∞–Ω –±–æ–ª–Ω–æ.

```{python}
#| echo: true
#| eval: false

# –ë“Ø—Ç—ç–Ω ”©–≥”©–≥–¥–ª–∏–π–≥ —É–Ω—à–∏—Ö (1.6 —Å–∞—è –º”©—Ä)
df_full = pd.read_csv("training.1600000.processed.noemoticon.csv", 
                      encoding="latin-1", header=None)

# 50,000 –º”©—Ä–∏–π–≥ —Å–∞–Ω–∞–º—Å–∞—Ä–≥“Ø–π–≥—ç—ç—Ä —Ç“Ø“Ø–≤—ç—Ä–ª—ç—Ö (Seed = 42)
df = df_full.sample(n=50000, random_state=42)
```

## ”®–≥”©–≥–¥–ª–∏–π–≥ —Ü—ç–≤—ç—Ä–ª—ç—Ö –±–∞ –ë—ç–ª—Ç–≥—ç—Ö (Preprocessing)

–¢“Ø“Ø—Ö–∏–π ”©–≥”©–≥–¥”©–ª (Raw Data) –Ω—å –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç —Ö–∏–π—Ö—ç–¥ —Å–∞–∞–¥ –±–æ–ª–æ—Ö –æ–ª–æ–Ω —Ç”©—Ä–ª–∏–π–Ω "—à—É—É–≥–∏–∞–Ω" (noise) –∞–≥—É—É–ª–¥–∞–≥. Python —Ö—ç–ª–Ω–∏–π `re` (Regular Expression) —Å–∞–Ω–≥ –∞—à–∏–≥–ª–∞–Ω —Ç–µ–∫—Å—Ç—ç–Ω ”©–≥”©–≥–¥–ª–∏–π–≥ –¥–∞—Ä–∞–∞—Ö –±–∞–π–¥–ª–∞–∞—Ä —Ü—ç–≤—ç—Ä–ª—ç–ª—ç—ç.

1.  –ñ–∏–∂–∏–≥ “Ø—Å—ç–≥—Ç —à–∏–ª–∂“Ø“Ø–ª—ç—Ö: `lower()` —Ñ—É–Ω–∫—Ü –∞—à–∏–≥–ª–∞–Ω –±“Ø—Ö —Ç–µ–∫—Å—Ç–∏–π–≥ –∂–∏–∂–∏–≥ “Ø—Å—ç–≥ –±–æ–ª–≥–æ–≤.
2.  URL –±–æ–ª–æ–Ω –•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –Ω—ç—Ä: `http` –±–æ–ª–æ–Ω `@username` —Ö—ç–ª–±—ç—Ä–∏–π–Ω —Ö–æ–ª–±–æ–æ—Å—É—É–¥—ã–≥ —É—Å—Ç–≥–∞–≤.
3.  HTML —Ç—ç–º–¥—ç–≥—Ç: `&amp;` –≥—ç—Ö –º—ç—Ç –∫–æ–¥—ã–≥ `and` –≥—ç—Ö –º—ç—Ç —ç–Ω–≥–∏–π–Ω “Ø–≥—ç—ç—Ä —Å–æ–ª–∏–≤.
4.  RT (Retweet): –ñ–∏—Ä–≥—ç—ç–≥ –¥–∞–º–∂—É—É–ª—Å–∞–Ω —Ç—ç–º–¥—ç–≥–ª—ç–≥—ç—ç–≥ —Ö–∞—Å–∞–≤.
5.  –¢—É—Å–≥–∞–π —Ç—ç–º–¥—ç–≥—Ç: “Æ—Å—ç–≥ –±–æ–ª–æ–Ω —Ç–æ–æ–Ω–æ–æ—Å –±—É—Å–∞–¥ —Ç—ç–º–¥—ç–≥—Ç“Ø“Ø–¥–∏–π–≥ —É—Å—Ç–≥–∞–≤.

```{python}
#| echo: true

import re

def clean_tweet(text):
    text = str(text).lower()                                # –ñ–∏–∂–∏–≥ “Ø—Å—ç–≥ –±–æ–ª–≥–æ—Ö
    text = re.sub(r"http\S+|www\.\S+", "", text)            # URL —É—Å—Ç–≥–∞—Ö
    text = re.sub(r"@\w+", "", text)                        # @username —É—Å—Ç–≥–∞—Ö
    text = re.sub(r"&amp;", "and", text)                    # &amp ‚Üí and –±–æ–ª–≥–æ—Ö
    text = re.sub(r"rt[\s]+", "", text)                     # RT (retweet) —É—Å—Ç–≥–∞—Ö
    text = re.sub(r"[^a-z0-9\s]", " ", text)                # –¢—É—Å–≥–∞–π —Ç—ç–º–¥—ç–≥—Ç —É—Å—Ç–≥–∞—Ö
    text = re.sub(r"\s+", " ", text).strip()                # –ò–ª“Ø“Ø–¥—ç–ª –∑–∞–π —Ü—ç–≤—ç—Ä–ª—ç—Ö
    return text

# ”®–≥”©–≥–¥–ª–∏–π–≥ —Ü—ç–≤—ç—Ä–ª—ç—Ö (–ñ–∏—à—ç—ç ”©–≥”©–≥–¥”©–ª –¥—ç—ç—Ä)
df_sample["clean_text"] = df_sample["text"].astype(str).apply(clean_tweet)

# Target —Ö—É–≤—å—Å–∞–≥—á–∏–π–≥ 0 (–°”©—Ä”©–≥) –±–∞ 1 (–≠–µ—Ä—ç–≥) –±–æ–ª–≥–æ–∂ —Ö”©—Ä–≤“Ø“Ø–ª—ç—Ö
# (Sentiment140 ”©–≥”©–≥–¥”©–ª–¥ 4 –Ω—å –≠–µ—Ä—ç–≥ –±–∞–π–¥–∞–≥)
if set(df_sample["target"].unique()) == {0, 4}:
    df_sample["target"] = df_sample["target"].map({0: 0, 4: 1})
```

–¶—ç–≤—ç—Ä–ª—ç–≥—ç—ç —Ö–∏–π—Å–Ω–∏–π –¥–∞—Ä–∞–∞—Ö “Ø—Ä –¥“Ø–Ω–≥ @tbl-clean-preview —Ö–∞—Ä—É—É–ª–∞–≤.

```{python}
#| echo: false
#| label: tbl-clean-preview
#| tbl-cap: –¶—ç–≤—ç—Ä–ª—ç—Å—ç–Ω ”©–≥”©–≥–¥–ª–∏–π–Ω –∂–∏—à—ç—ç

from IPython.display import Markdown

# –•–∞—Ä—É—É–ª–∞—Ö –±–∞–≥–∞–Ω—É—É–¥–∞–∞ —Å–æ–Ω–≥–æ—Ö
subset_clean = df_sample[["target", "text", "clean_text"]].sample(n=5, random_state=1).copy()
subset_clean.columns = ["–ê–Ω–≥–∏–ª–∞–ª", "–≠—Ö —Ç–µ–∫—Å—Ç", "–¶—ç–≤—ç—Ä —Ç–µ–∫—Å—Ç"]

# –£—Ä—Ç —Ç–µ–∫—Å—Ç–∏–π–≥ —Ç–∞–π—Ä–∞—Ö (PDF –¥—ç—ç—Ä –±–∞–≥—Ç–∞–∞—Ö—ã–Ω —Ç—É–ª–¥)
subset_clean["–≠—Ö —Ç–µ–∫—Å—Ç"] = subset_clean["–≠—Ö —Ç–µ–∫—Å—Ç"].str.slice(0, 40) + "..."
subset_clean["–¶—ç–≤—ç—Ä —Ç–µ–∫—Å—Ç"] = subset_clean["–¶—ç–≤—ç—Ä —Ç–µ–∫—Å—Ç"].str.slice(0, 40) + "..."

Markdown(subset_clean.to_markdown(index=False))
```

## ”®–≥”©–≥–¥–ª–∏–π–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç (EDA)
–°—É—Ä–≥–∞–ª—Ç–∞–¥ –∞—à–∏–≥–ª–∞–∂ –±—É–π ”©–≥”©–≥–¥–ª–∏–π–Ω —Ç—ç–Ω—Ü–≤—ç—Ä—Ç—ç–π –±–∞–π–¥–ª—ã–≥ —à–∞–ª–≥–∞—Ö –Ω—å —á—É—Ö–∞–ª —é–º. –ë–∏–¥–Ω–∏–π –∞—à–∏–≥–ª–∞–∂ –±—É–π —Ç“Ø“Ø–≤—ç—Ä ”©–≥”©–≥–¥”©–ª–¥ –°”©—Ä”©–≥ (0) –±–æ–ª–æ–Ω –≠–µ—Ä—ç–≥ (1) –∞–Ω–≥–∏–ª–∞–ª —Ö—ç—Ä—Ö—ç–Ω —Ç–∞—Ä—Ö—Å–∞–Ω—ã–≥ @fig-countplot –¥–∏–∞–≥—Ä–∞–º–º–∞–∞—Ä —Ö–∞—Ä—É—É–ª–∞–≤.

```{python}
#| warning: false
#| label: fig-countplot
#| fig-cap: –°—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª–∏–π–Ω –∞–Ω–≥–∏–ª–ª—ã–Ω —Ç–∞—Ä—Ö–∞–ª—Ç

import matplotlib.pyplot as plt
import seaborn as sns

# –ì—Ä–∞—Ñ–∏–∫–∏–π–Ω —Ö—ç–º–∂—ç—ç–≥ —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö
plt.figure(figsize=(6, 3))

# Countplot –∑—É—Ä–∞—Ö
ax = sns.countplot(x=df_sample["target"], palette="viridis")

for container in ax.containers:
	ax.bar_label(container, fmt='%d', color='white', label_type='center')

# –¢—ç–Ω—Ö–ª—ç–≥–∏–π–Ω –Ω—ç—Ä—Å
plt.xticks([0, 1], ["–°”©—Ä”©–≥ (0)", "–≠–µ—Ä—ç–≥ (1)"])
plt.xlabel("–°—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª")
plt.ylabel("–ñ–∏—Ä–≥—ç—ç–Ω–∏–π —Ç–æ–æ")
plt.title("”®–≥”©–≥–¥–ª–∏–π–Ω —Ç—ç–Ω—Ü–≤—ç—Ä—Ç—ç–π –±–∞–π–¥–∞–ª")
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()
```

–î–∏–∞–≥—Ä–∞–º–º–∞–∞—Å —Ö–∞—Ä–∞—Ö–∞–¥ ”©–≥”©–≥–¥”©–ª —Ç—ç–Ω—Ü–≤—ç—Ä—Ç—ç–π –±–∞–π–≥–∞–∞ –Ω—å –∑–∞–≥–≤–∞—Ä –∞–ª—å –Ω—ç–≥ —Ç–∞–ª —Ä—É—É —Ö—ç—Ç —Ö–∞–∑–∞–π—Ö (bias) —ç—Ä—Å–¥—ç–ª–≥“Ø–π–≥ —Ö–∞—Ä—É—É–ª–∂ –±–∞–π–Ω–∞.

# –°—É–¥–∞–ª–≥–∞–∞–Ω—ã –∞—Ä–≥–∞ –∑“Ø–π

–≠–Ω—ç—Ö“Ø“Ø —Å—É–¥–∞–ª–≥–∞–∞–Ω–¥ –±–∏–¥ —Ç–µ–∫—Å—Ç—ç–Ω –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –∞–Ω–≥–∏–ª–∞—Ö–¥–∞–∞ **—Ö—è–Ω–∞–ª—Ç—Ç–∞–π –º–∞—à–∏–Ω —Å—É—Ä–≥–∞–ª—Ç—ã–Ω** (Supervised Machine Learning) —Ç“Ø–≥—ç—ç–º—ç–ª –∞—Ä–≥—É—É–¥ –±–æ–ª–æ—Ö **–ì—ç–Ω—ç–Ω –ë–∞–π–µ—Å** –±–æ–ª–æ–Ω **–õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å** –∑–∞–≥–≤–∞—Ä—É—É–¥—ã–≥ –∞—à–∏–≥–ª–∞–≤.

## –í–µ–∫—Ç–æ—Ä–∂—É—É–ª–∞—Ö –∞—Ä–≥–∞ (Feature Extraction)

–ú–∞—à–∏–Ω —Å—É—Ä–≥–∞–ª—Ç—ã–Ω –∑–∞–≥–≤–∞—Ä—É—É–¥ –Ω—å —Ç–µ–∫—Å—Ç–∏–π–≥ —à—É—É–¥ –æ–π–ª–≥–æ—Ö –±–æ–ª–æ–º–∂–≥“Ø–π —Ç—É–ª –±–∏–¥ —Ç—ç–¥–≥—ç—ç—Ä–∏–π–≥ —Ç–æ–æ–Ω —Ö—ç–ª–±—ç—Ä—Ç —à–∏–ª–∂“Ø“Ø–ª—ç—Ö —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π. “Æ“Ø–Ω–¥ –¥–∞—Ä–∞–∞—Ö —Ö–æ—ë—Ä –∞—Ä–≥—ã–≥ –∞—à–∏–≥–ª–∞–≤:

1.  **CountVectorizer (Bag of Words):** “Æ–≥—Å–∏–π–Ω –¥–∞–≤—Ç–∞–º–∂–∏–π–≥ —Ç–æ–æ–ª–æ—Ö —ç–Ω–≥–∏–π–Ω –∞—Ä–≥–∞.
2.  **TF-IDF (Term Frequency-Inverse Document Frequency):** “Æ–≥—Å–∏–π–Ω –¥–∞–≤—Ç–∞–º–∂–∏–π–≥ –Ω–∏–π—Ç –±–∞—Ä–∏–º—Ç –±–∏—á–∏–≥—Ç —ç–∑–ª—ç—Ö —Ö—É–≤–∏–∞—Ä –∂–∏–Ω–ª—ç–Ω “Ø–Ω—ç–ª—ç—Ö –∞—Ä–≥–∞.

## –ì—ç–Ω—ç–Ω –ë–∞–π–µ—Å—ã–Ω –∞–ª–≥–æ—Ä–∏—Ç–º (Naive Bayes)

–≠–Ω—ç –Ω—å –ë–∞–π–µ—Å—ã–Ω –∑–∞—Ä—á–∏–º–¥ —Å—É—É—Ä–∏–ª—Å–∞–Ω –∞–Ω–≥–∏–ª–ª—ã–Ω –∞–ª–≥–æ—Ä–∏—Ç–º —é–º. –õ–µ–∫—Ü XVI @lecture_notes –¥—É—Ä–¥—Å–∞–Ω–∞–∞—Ä —é–º—Å “Ø–∑—ç–≥–¥–ª–∏–π–≥ —Ö–∞–º–≥–∏–π–Ω –∏—Ö **–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä –º–∞–≥–∞–¥–ª–∞–ª—Ç–∞–π** –∞–Ω–≥–∏–¥ —Ö—É–≤–∞–∞—Ä–∏–ª–¥–∞–≥:

$$ \operatorname{argmax}_{k} P(C_k) \prod_{i=1}^{n} P(X_i|C_k) $$

–≠–Ω–¥:

*   $P(C_k)$: –ü—Ä–∏–æ—Ä –º–∞–≥–∞–¥–ª–∞–ª (–¢—É—Ö–∞–π–Ω –∞–Ω–≥–∏–ª–ª—ã–Ω –µ—Ä”©–Ω—Ö–∏–π –º–∞–≥–∞–¥–ª–∞–ª).
*   $P(X_i|C_k)$: “Æ–Ω—ç–Ω–∏–π —Ö—É–≤—å (Likelihood) –±—É—é—É —Ç—É—Ö–∞–π–Ω –∞–Ω–≥–∏–ª–∞–ª–¥ $X_i$ —à–∏–Ω–∂ —á–∞–Ω–∞—Ä (“Ø–≥) –∏–ª—Ä—ç—Ö –º–∞–≥–∞–¥–ª–∞–ª.
*   $\prod$: “Æ—Ä–∂–≤—ç—Ä (–ë“Ø—Ö “Ø–≥—Å–∏–π–Ω –º–∞–≥–∞–¥–ª–∞–ª—ã–≥ —Ö–æ–æ—Ä–æ–Ω–¥ –Ω—å “Ø—Ä–∂“Ø“Ø–ª–∂ –±–∞–π–Ω–∞).

–ë–∏–¥ —ç–Ω—ç—Ö“Ø“Ø —Ç”©—Å”©–ª–¥ `MultinomialNB` —Ö—É–≤–∏–ª–±–∞—Ä—ã–≥ –∞—à–∏–≥–ª–∞—Å–∞–Ω.

## –õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å (Logistic Regression)

–õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å –Ω—å “Ø—Ä –¥“Ø–Ω–≥ 0-—ç—ç—Å 1-–∏–π–Ω —Ö–æ–æ—Ä–æ–Ω–¥ –º–∞–≥–∞–¥–ª–∞–ª–∞–∞—Ä –∏–ª—ç—Ä—Ö–∏–π–ª–¥—ç–≥. –õ–µ–∫—Ü XVI @lecture_notes –¥—É—Ä–¥—Å–∞–Ω–∞–∞—Ä —ç–Ω—ç –Ω—å —à—É–≥–∞–º–∞–Ω —Ä–µ–≥—Ä–µ—Å—Å–∏–π–Ω —É—Ç–≥—ã–≥ **–ª–æ–∂–∏—Å—Ç–∏–∫ —Ñ—É–Ω–∫—Ü** –∞—à–∏–≥–ª–∞–Ω —Ö—É–≤–∏—Ä–≥–∞–¥–∞–≥:

$$ p = \frac{e^{a+bX}}{1 + e^{a+bX}} $$

–≠–Ω–¥:

*   $p$: –ñ–∏—Ä–≥—ç—ç —ç–µ—Ä—ç–≥ –±–∞–π—Ö –º–∞–≥–∞–¥–ª–∞–ª.
*   $a+bX$: –¢–µ–∫—Å—Ç—ç–Ω ”©–≥”©–≥–¥–ª–∏–π–Ω —à–∏–Ω–∂ —á–∞–Ω–∞—Ä—É—É–¥—ã–Ω —à—É–≥–∞–º–∞–Ω —Ö–æ—Å–ª–æ–ª.
*   $e$: –ù–∞—Ç—É—Ä—ã–Ω –ª–æ–≥–∞—Ä–∏—Ñ–º—ã–Ω —Å—É—É—Ä—å.

–≠–Ω—ç –∞—Ä–≥–∞ –Ω—å —Ö—É–≤—å—Å–∞–≥—á–¥—ã–Ω –Ω–∞—Ä–∏–π–Ω —Ö–∞–º–∞–∞—Ä–ª—ã–≥ –∏–ª—Ä“Ø“Ø–ª—ç—Ö–¥—ç—ç —Å–∞–π–Ω –∞–∂–∏–ª–ª–∞–¥–∞–≥ –±”©–≥”©”©–¥ “Ø—Ä –¥“Ø–Ω–≥ –º–∞–≥–∞–¥–ª–∞–ª–∞–∞—Ä –∏–ª—ç—Ä—Ö–∏–π–ª–¥—ç–≥ –¥–∞–≤—É—É —Ç–∞–ª—Ç–∞–π.

# –¢—É—Ä—à–∏–ª—Ç –±–∞ “Æ—Ä –¥“Ø–Ω

–ë–∏–¥ –±–æ–ª–æ–≤—Å—Ä—É—É–ª—Å–∞–Ω 50,000 –º”©—Ä ”©–≥”©–≥–¥–ª–∏–π–≥ —Å—É—Ä–≥–∞–ª—Ç—ã–Ω (Training set) –±–æ–ª–æ–Ω —Ç–µ—Å—Ç–∏–π–Ω (Test set) –æ–ª–æ–Ω–ª–æ–≥—Ç **70:30** —Ö–∞—Ä—å—Ü–∞–∞—Ç–∞–π–≥–∞–∞—Ä —Å–∞–Ω–∞–º—Å–∞—Ä–≥“Ø–π–≥—ç—ç—Ä —Ö—É–≤–∞–∞—Å–∞–Ω. –ò–Ω–≥—ç—Ö–¥—ç—ç –∞–Ω–≥–∏–ª–ª—ã–Ω —Ç—ç–Ω—Ü–≤—ç—Ä—Ç—ç–π –±–∞–π–¥–ª—ã–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö—ã–Ω —Ç—É–ª–¥ `stratify` –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–π–≥ –∞—à–∏–≥–ª–∞–≤.

```{python}
#| echo: true
#| warning: false

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# ”®–≥”©–≥–¥–ª–∏–π–≥ –±—ç–ª—Ç–≥—ç—Ö (”®–º–Ω”©—Ö —Ö—ç—Å—ç–≥—Ç —Ü—ç–≤—ç—Ä–ª—ç—Å—ç–Ω df_sample-–≥ –∞—à–∏–≥–ª–∞–Ω–∞)
# clean_text –±–∞–≥–∞–Ω–∞–¥ NaN –±–∞–π—Ö–≥“Ø–π —ç—Å—ç—Ö–∏–π–≥ —à–∞–ª–≥–∞–∞–¥ string –±–æ–ª–≥–æ—Ö
X = df_sample["clean_text"].fillna("").astype(str)
y = df_sample["target"]

# 70% —Å—É—Ä–≥–∞–ª—Ç, 30% —Ç–µ—Å—Ç
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# 1. Naive Bayes Pipeline
nb_model = Pipeline([
    ("vect", CountVectorizer(max_features=15000, ngram_range=(1,2))),
    ("clf", MultinomialNB())
])

# 2. Logistic Regression Pipeline
lr_model = Pipeline([
    ("vect", TfidfVectorizer(max_features=20000, ngram_range=(1,2))),
    ("clf", LogisticRegression(max_iter=1000, solver="liblinear"))
])

# –ó–∞–≥–≤–∞—Ä—É—É–¥—ã–≥ —Å—É—Ä–≥–∞—Ö
nb_model.fit(X_train, y_train)
lr_model.fit(X_train, y_train)

# –¢–∞–∞–º–∞–≥–ª–∞–ª –¥—ç–≤—à“Ø“Ø–ª—ç—Ö
y_pred_nb = nb_model.predict(X_test)
y_pred_lr = lr_model.predict(X_test)

# –ù–∞—Ä–∏–π–≤—á–ª–∞–ª —Ç–æ–æ—Ü–æ—Ö
acc_nb = accuracy_score(y_test, y_pred_nb)
acc_lr = accuracy_score(y_test, y_pred_lr)
```

## –ó–∞–≥–≤–∞—Ä—É—É–¥—ã–Ω —Ö–∞—Ä—å—Ü—É—É–ª–∞–ª—Ç

–¢—É—Ä—à–∏–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω–¥ —Ö–æ—ë—Ä –∑–∞–≥–≤–∞—Ä—ã–Ω –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—ã–≥ @tbl-accuracy —Ö–∞—Ä—å—Ü—É—É–ª–∞–Ω —Ö–∞—Ä—É—É–ª–∞–≤. –ë–∏–¥–Ω–∏–π —Ç–∞–∞–º–∞–≥–ª–∞–∂ –±–∞–π—Å–Ω–∞–∞—Ä –õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å –∑–∞–≥–≤–∞—Ä –Ω—å –∏–ª“Ø“Ø ”©–Ω–¥”©—Ä “Ø—Ä –¥“Ø–Ω “Ø–∑“Ø“Ø–ª–ª—ç—ç.

| –ó–∞–≥–≤–∞—Ä | –ù–∞—Ä–∏–π–≤—á–ª–∞–ª (Accuracy) | –¢–∞–π–ª–±–∞—Ä |
| :--- | :--- | :--- |
| **–ì—ç–Ω—ç–Ω –ë–∞–π–µ—Å** | `{python} f"{acc_nb*100:.2f}%"` | –•—É—Ä–¥–∞–Ω –∞–∂–∏–ª–ª–∞–¥–∞–≥ –±–æ–ª–æ–≤—á “Ø–≥—Å–∏–π–Ω —Ö–∞–º–∞–∞—Ä–ª—ã–≥ —Ç–æ–æ—Ü–¥–æ–≥–≥“Ø–π. |
| **–õ–æ–∂–∏—Å—Ç–∏–∫ –†–µ–≥—Ä–µ—Å—Å** | `{python} f"{acc_lr*100:.2f}%"` | TF-IDF –∂–∏–Ω–ª—ç–ª—Ç –∞—à–∏–≥–ª–∞—Å–∞–Ω —Ç—É–ª –∏–ª“Ø“Ø –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—Ç–∞–π. |

: –ó–∞–≥–≤–∞—Ä—É—É–¥—ã–Ω –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—ã–Ω —Ö–∞—Ä—å—Ü—É—É–ª–∞–ª—Ç {#tbl-accuracy}

## –¢”©”©—Ä”©–≥–¥–ª–∏–π–Ω –º–∞—Ç—Ä–∏—Ü (Confusion Matrix)

–ó–∞–≥–≤–∞—Ä —Ö—ç—Ä—Ö—ç–Ω –∞–∂–∏–ª–ª–∞—Å–Ω—ã–≥ –∏–ª“Ø“Ø –Ω–∞—Ä–∏–π–≤—á–ª–∞–Ω —Ö–∞—Ä–∞—Ö—ã–Ω —Ç—É–ª–¥ ”©–Ω–¥”©—Ä “Ø—Ä –¥“Ø–Ω “Ø–∑“Ø“Ø–ª—Å—ç–Ω –õ–æ–∂–∏—Å—Ç–∏–∫ –†–µ–≥—Ä–µ—Å—Å –∑–∞–≥–≤–∞—Ä—ã–Ω –¢”©”©—Ä”©–≥–¥–ª–∏–π–Ω –º–∞—Ç—Ä–∏—Ü—ã–≥ @fig-confusion-matrix –¥—ç—ç—Ä –¥“Ø—Ä—Å—ç–ª–ª—ç—ç. –≠–Ω—ç –Ω—å –∑–∞–≥–≤–∞—Ä "–°”©—Ä”©–≥" –±–æ–ª–æ–Ω "–≠–µ—Ä—ç–≥" –∂–∏—Ä–≥—ç—ç–≥ —Ö—ç—Ä –∑”©–≤ —è–ª–≥–∞–∂ –±–∞–π–≥–∞–∞–≥ —Ö–∞—Ä—É—É–ª–Ω–∞.

```{python}
#| label: fig-confusion-matrix
#| fig-cap: –õ–æ–∂–∏—Å—Ç–∏–∫ –†–µ–≥—Ä–µ—Å—Å –∑–∞–≥–≤–∞—Ä—ã–Ω –¢”©”©—Ä”©–≥–¥–ª–∏–π–Ω –º–∞—Ç—Ä–∏—Ü
#| warning: false
#| echo: true

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# –ú–∞—Ç—Ä–∏—Ü —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö
cm = confusion_matrix(y_test, y_pred_lr)

# –ì—Ä–∞—Ñ–∏–∫ –∑—É—Ä–∞—Ö
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", 
            xticklabels=["–°”©—Ä”©–≥ (Pred)", "–≠–µ—Ä—ç–≥ (Pred)"],
            yticklabels=["–°”©—Ä”©–≥ (True)", "–≠–µ—Ä—ç–≥ (True)"])
plt.title("Logistic Regression Confusion Matrix")
plt.show()
```

```{python}
#| echo: false
# –î“Ø–≥–Ω—ç–ª—Ç —Ö—ç—Å—ç–≥—Ç –∞—à–∏–≥–ª–∞—Ö —Ö—É–≤—å—Å–∞–≥—á–∏–¥ (–ê–≤—Ç–æ–º–∞—Ç–∞–∞—Ä –±”©–≥–ª”©–≥–¥”©–Ω”©)
conclusion.append(f"–°–∞–Ω–∞–º—Å–∞—Ä–≥“Ø–π —Ç“Ø“Ø–≤—ç—Ä–ª—ç—Å—ç–Ω {len(df_sample)} ”©–≥”©–≥–¥”©–ª –¥—ç—ç—Ä —Ç—É—Ä—à–∏–ª—Ç —Ö–∏–π—Ö—ç–¥ –õ–æ–∂–∏—Å—Ç–∏–∫ –†–µ–≥—Ä–µ—Å—Å –∑–∞–≥–≤–∞—Ä {acc_lr*100:.1f}% –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—Ç–∞–π –±–∞–π–≤.")
conclusion.append(f"–ì—ç–Ω—ç–Ω –ë–∞–π–µ—Å –∑–∞–≥–≤–∞—Ä ({acc_nb*100:.1f}%) –Ω—å —Ö—É—Ä–¥–∞–Ω –±–æ–ª–æ–≤—á –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª–∞–∞—Ä –±–∞–≥–∞ –∑—ç—Ä—ç–≥ –¥—É—Ç–º–∞–≥ –±–∞–π–≤.")
conclusion.append("–õ–æ–∂–∏—Ç –∑–∞–≥–≤–∞—Ä –±–æ–ª–æ–Ω TF-IDF –≤–µ–∫—Ç–æ—Ä–∂—É—É–ª–∞–ª—Ç –Ω—å —Å—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª–∏–π–≥ –∞–Ω–≥–∏–ª–∞—Ö–∞–¥ –∏–ª“Ø“Ø —Ç–æ—Ö–∏—Ä–æ–º–∂—Ç–æ–π –∞—Ä–≥–∞ –±–æ–ª–æ—Ö –Ω—å –±–∞—Ç–ª–∞–≥–¥–ª–∞–∞.")
```
## –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ —à–∏–Ω–∂–∏–ª–≥—ç—ç–Ω–∏–π —Å–∞–º–±–∞—Ä (Streamlit Dashboard)

–≠–Ω—ç—Ö“Ø“Ø —Ç–∞–π–ª–∞–Ω–¥ “Ø–∑“Ø“Ø–ª—Å—ç–Ω —Å—Ç–∞—Ç–∏–∫ “Ø—Ä –¥“Ø–Ω–≥—ç—ç—Å –≥–∞–¥–Ω–∞ –±–∏–¥ –∑–∞–≥–≤–∞—Ä—ã–Ω –∞–∂–∏–ª–ª–∞–≥–∞–∞–≥ –±–æ–¥–∏—Ç —Ö—É–≥–∞—Ü–∞–∞–Ω–¥ —Ç—É—Ä—à–∏—Ö, –Ω–∞—Ä–∏–π–≤—á–ª–∞–Ω —à–∏–Ω–∂–ª—ç—Ö –∑–æ—Ä–∏–ª–≥–æ–æ—Ä **Streamlit** –¥—ç—ç—Ä —Å—É—É—Ä–∏–ª—Å–∞–Ω –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ –≤–µ–± —Å–∞–º–±–∞—Ä (Dashboard) —Ö”©–≥–∂“Ø“Ø–ª—Å—ç–Ω.

–≠–Ω—ç—Ö“Ø“Ø —Å–∞–º–±–∞—Ä—ã–≥ —Ö”©–≥–∂“Ø“Ø–ª—ç—Ö–¥—ç—ç –±–∏–¥ –ë—Ä–∞—É–Ω—ã –ò—Ö –°—É—Ä–≥—É—É–ª–∏–π–Ω **"Seeing Theory"** @seeing_theory —Ç”©—Å–ª”©”©—Å —Å–∞–Ω–∞–∞ –∞–≤—á, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –æ–π–ª–≥–æ–ª—Ç—É—É–¥ –±–æ–ª–æ–Ω –º–∞–≥–∞–¥–ª–∞–ª—ã–Ω —Ç–∞—Ä—Ö–∞–ª—Ç—ã–≥ –≤–∏–∑—É–∞–ª —Ö—ç–ª–±—ç—Ä—ç—ç—Ä, –æ–π–ª–≥–æ–º–∂—Ç–æ–π —Ö–∞—Ä—É—É–ª–∞—Ö—ã–≥ –∑–æ—Ä—å—Å–æ–Ω –±–æ–ª–Ω–æ.

–≠–Ω—ç—Ö“Ø“Ø —Å–∞–º–±–∞—Ä –Ω—å –¥–∞—Ä–∞–∞—Ö –±–æ–ª–æ–º–∂—É—É–¥—ã–≥ –æ–ª–≥–æ–Ω–æ:

1.  **”®–≥”©–≥–¥–ª–∏–π–Ω –¥–∏–Ω–∞–º–∏–∫ —Ö—É–≤–∞–∞—Ä–∏–ª–∞–ª—Ç:** `Slider` –∞—à–∏–≥–ª–∞–Ω —Å—É—Ä–≥–∞–ª—Ç—ã–Ω –±–æ–ª–æ–Ω —Ç–µ—Å—Ç–∏–π–Ω ”©–≥”©–≥–¥–ª–∏–π–Ω —Ö–∞—Ä—å—Ü–∞–∞–≥ (Train/Test Split) –¥—É—Ä—ã–Ω –±–∞–π–¥–ª–∞–∞—Ä ”©”©—Ä—á–∏–ª–∂, –∑–∞–≥–≤–∞—Ä—ã–Ω –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª —Ö—ç—Ä—Ö—ç–Ω ”©”©—Ä—á–ª”©–≥–¥”©–∂ –±—É–π–≥ —Ö–∞—Ä–∞—Ö.
2.  **–ü–æ—Å—Ç–µ—Ä–∏–æ—Ä –º–∞–≥–∞–¥–ª–∞–ª—ã–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç:** –°–æ–Ω–≥–æ—Å–æ–Ω –∂–∏—Ä–≥—ç—ç —Ç—É—Å –±“Ø—Ä –¥—ç—ç—Ä –∑–∞–≥–≤–∞—Ä —Ö—ç–¥—ç–Ω —Ö—É–≤–∏–π–Ω –º–∞–≥–∞–¥–ª–∞–ª—Ç–∞–π–≥–∞–∞—Ä —Ç–∞–∞–º–∞–≥–ª–∞–ª –¥—ç–≤—à“Ø“Ø–ª–∂ –±–∞–π–≥–∞–∞–≥ —Ö–∞—Ä–∞—Ö.
3.  **3D –í–∏–∑—É–∞–ª—á–ª–∞–ª:** –ú–∞–≥–∞–¥–ª–∞–ª—ã–Ω —Ç–∞—Ä—Ö–∞–ª—Ç—ã–≥ 3 —Ö—ç–º–∂—ç—ç—Å—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞–∞—Ä —Ö–∞—Ä—É—É–ª–∞—Ö.
4.  **–•–∞—Ä–∏—Ü—É—É–ª—Å–∞–Ω “Ø–Ω—ç–ª–≥—ç—ç:** –ì—ç–Ω—ç–Ω –ë–∞–π–µ—Å –±–æ–ª–æ–Ω –õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å –∑–∞–≥–≤–∞—Ä—É—É–¥—ã–Ω —Ç–∞–∞–º–∞–≥–ª–∞–ª —Ö–∞–∞–Ω–∞ –∑”©—Ä–∂ –±–∞–π–≥–∞–∞–≥ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ –≥—Ä–∞—Ñ–∏–∫–∞–∞—Ä —à–∏–Ω–∂–ª—ç—Ö.

–≠–Ω—ç—Ö“Ø“Ø —Ö—ç—Ä—ç–≥–ª“Ø“Ø—Ä –Ω—å –∑–∞–≥–≤–∞—Ä—ã–Ω –¥–∞–≤—É—É –±–æ–ª–æ–Ω —Å—É–ª —Ç–∞–ª—ã–≥ "—Ö–∞—Ä —Ö–∞–π—Ä—Ü–∞–≥" (black box) —Ö—ç–ª–±—ç—Ä—ç—ç—Ä –±–∏—à, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ “Ø–Ω–¥—ç—Å–ª—ç–ª—Ç—ç–π–≥—ç—ç—Ä –Ω—ç—ç–ª—Ç—Ç—ç–π —Ö–∞—Ä–∞—Ö –±–æ–ª–æ–º–∂–∏–π–≥ –æ–ª–≥–æ–∂ –±—É–π–≥ –æ–Ω—Ü–ª—É—É—à—Ç–∞–π —é–º.


# –î“Ø–≥–Ω—ç–ª—Ç

–≠–Ω—ç—Ö“Ø“Ø —Ç”©—Å–ª–∏–π–Ω —Ö“Ø—Ä—ç—ç–Ω–¥ –±–∏–¥ –Ω–∏–π–≥–º–∏–π–Ω —Å“Ø–ª–∂—ç—ç–Ω–∏–π "Sentiment140" ”©–≥”©–≥–¥”©–ª –¥—ç—ç—Ä —Ç—É–ª–≥—É—É—Ä–ª–∞–Ω —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Å—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª–∏–π–≥ –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä –∞–Ω–≥–∏–ª–∞—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∑–∞–≥–≤–∞—Ä—É—É–¥—ã–≥ —Ö”©–≥–∂“Ø“Ø–ª–∂, “Ø—Ä –¥“Ø–Ω–≥ —Ö–∞—Ä—å—Ü—É—É–ª–ª–∞–∞. –¢—É—Ä—à–∏–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω–¥ “Ø–Ω–¥—ç—Å–ª—ç–Ω –¥–∞—Ä–∞–∞—Ö –¥“Ø–≥–Ω—ç–ª—Ç“Ø“Ø–¥–∏–π–≥ –≥–∞—Ä–≥–∞–∂ –±–∞–π–Ω–∞:

```{python}
#| echo: false

from IPython.display import Markdown

lr_score = f"{acc_lr*100:.1f}%"
nb_score = f"{acc_nb*100:.1f}%"
diff_val = (acc_lr - acc_nb) * 100
diff_score = f"{diff_val:.1f}%"

final_conclusion = []

final_conclusion.append(
    f"–°–∞–Ω–∞–º—Å–∞—Ä–≥“Ø–π —Ç“Ø“Ø–≤—ç—Ä–ª—ç—Å—ç–Ω 50,000 ”©–≥”©–≥–¥”©–ª –¥—ç—ç—Ä —Ç—É—Ä—à–∏–ª—Ç —Ö–∏–π—Ö—ç–¥ **–õ–æ–∂–∏—Å—Ç–∏–∫ –†–µ–≥—Ä–µ—Å—Å** –∑–∞–≥–≤–∞—Ä **{lr_score}** –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—Ç–∞–π–≥–∞–∞—Ä —Ö–∞–º–≥–∏–π–Ω ”©–Ω–¥”©—Ä “Ø—Ä –¥“Ø–Ω “Ø–∑“Ø“Ø–ª–ª—ç—ç."
)

final_conclusion.append(
    f"**–ì—ç–Ω—ç–Ω –ë–∞–π–µ—Å** –∑–∞–≥–≤–∞—Ä (**{nb_score}**) –Ω—å —Ö—É—Ä–¥–∞–Ω –∞–∂–∏–ª–ª–∞–≥–∞–∞—Ç–∞–π –±–æ–ª–æ–≤—á –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª–∞–∞—Ä –õ–æ–∂–∏—Å—Ç–∏–∫ –∑–∞–≥–≤–∞—Ä–∞–∞—Å –±–∞–≥–∞ –∑—ç—Ä—ç–≥ –¥—É—Ç–º–∞–≥ –±–∞–π–≤."
)

final_conclusion.append(
    "–õ–æ–∂–∏—Ç –∑–∞–≥–≤–∞—Ä –±–æ–ª–æ–Ω TF-IDF –≤–µ–∫—Ç–æ—Ä–∂—É—É–ª–∞–ª—Ç –Ω—å “Ø–≥—Å–∏–π–Ω –¥–∞–≤—Ç–∞–º–∂–∞–∞—Å –≥–∞–¥–Ω–∞ —Ç—ç–¥–≥—ç—ç—Ä–∏–π–Ω —á—É—Ö–∞–ª—á–ª–∞—Ö –∂–∏–Ω–≥ —Ç–æ–æ—Ü–¥–æ–≥ —Ç—É–ª —Å—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª–∏–π–≥ –∞–Ω–≥–∏–ª–∞—Ö–∞–¥ –∏–ª“Ø“Ø —Ç–æ—Ö–∏—Ä–æ–º–∂—Ç–æ–π –∞—Ä–≥–∞ –±–æ–ª–æ—Ö –Ω—å –±–∞—Ç–ª–∞–≥–¥–ª–∞–∞."
)

if acc_lr > acc_nb:
    final_conclusion.append(
        f"–•—ç–¥–∏–π–≥—ç—ç—Ä –õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å –∏–ª“Ø“Ø –±–∞–π—Å–∞–Ω —á, —Ö–æ—ë—Ä –∑–∞–≥–≤–∞—Ä—ã–Ω –∑”©—Ä“Ø“Ø –µ—Ä–¥”©”© **{diff_score}** –±–∞–π–≥–∞–∞ –Ω—å —Ç—É—Å ”©–≥”©–≥–¥–ª–∏–π–Ω —Ö—É–≤—å–¥ “Ø–≥—Å–∏–π–Ω —Ö–∞–º–∞–∞—Ä–∞–ª (Logistic) –±–æ–ª–æ–Ω —Ç—É—Å–≥–∞–∞—Ä –±–∞–π–¥–∞–ª (Naive Bayes) —Ö–æ—ë—É–ª–∞–∞ –º—ç–¥—ç—ç–ª—ç–ª —Å–∞–π—Ç–∞–π–≥ —Ö–∞—Ä—É—É–ª–∂ –±–∞–π–Ω–∞."
    )

final_conclusion.append(
    "**–Å—Å –∑“Ø–π:** –ë–∏–¥ —Å—É–¥–∞–ª–≥–∞–∞–Ω–¥–∞–∞ —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Ö—É–≤–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª (User ID)-–∏–π–≥ –∑–∞–≥–≤–∞—Ä—á–ª–∞–ª–¥ –∞—à–∏–≥–ª–∞–∞–≥“Ø–π –±”©–≥”©”©–¥ –∑”©–≤—Ö”©–Ω –Ω–∏–π—Ç—ç–¥ –∏–ª —Ç–æ–¥ –±–∞–π–≥–∞–∞ –∂–∏—Ä–≥—ç—ç–Ω–∏–π —Ç–µ–∫—Å—Ç—ç–¥ –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç —Ö–∏–π—Å—ç–Ω –±–æ–ª–Ω–æ."
)

md_text = ""
for i, item in enumerate(final_conclusion, 1):
    md_text += f"{i}. {item}\n\n"

Markdown(md_text)
```

# –ë–∞–≥–∏–π–Ω –≥–∏—à“Ø“Ø–¥–∏–π–Ω –æ—Ä–æ–ª—Ü–æ–æ {.unnumbered}

–¢”©—Å–ª–∏–π–Ω –∞–∂–∏–ª–¥ –±–∞–≥–∏–π–Ω –≥–∏—à“Ø“Ø–¥–∏–π–Ω –æ—Ä—É—É–ª—Å–∞–Ω —Ö—É–≤—å –Ω—ç–º—ç—Ä –±–∞ –≥“Ø–π—Ü—ç—Ç–≥—ç—Å—ç–Ω “Ø“Ø—Ä–≥–∏–π–≥ –¥–æ–æ—Ä—Ö —Ö“Ø—Å–Ω—ç–≥—Ç—ç–¥ —Ö–∞—Ä—É—É–ª–∞–≤.

| –û—é—É—Ç–Ω—ã –ù—ç—Ä | –ì“Ø–π—Ü—ç—Ç–≥—ç—Å—ç–Ω “Ø“Ø—Ä—ç–≥ | –û—Ä–æ–ª—Ü–æ–æ (%) |
| :--- | :--- | :---: |
| **–õ.–ê–Ω—É–∂–∏–Ω** | | |
| **–ì.–ë–∞—Ç–Ω—è–º** | | |
| **–≠.–ú—ç–Ω–¥–±–∞—è—Ä** | | |
| **–ë.–•—É–≤—å–∑–∞—è–∞** | | |
| **–ê.–≠—Ä—Ö—ç—Å** | | |

# –ê—à–∏–≥–ª–∞—Å–∞–Ω –º–∞—Ç–µ—Ä–∏–∞–ª {.unnumbered}

::: {#refs}
:::

# –•–∞–≤—Å—Ä–∞–ª—Ç: –ü—Ä–æ–≥—Ä–∞–º—ã–Ω –∫–æ–¥ {.unnumbered}

–¢”©—Å–ª–∏–π–Ω “Ø–Ω–¥—Å—ç–Ω –∫–æ–¥ –±–æ–ª–æ—Ö `main.py` —Ñ–∞–π–ª—ã–Ω –±“Ø—Ä—ç–Ω —ç—Ö –∫–æ–¥—ã–≥ –¥–æ–æ—Ä —Ö–∞—Ä—É—É–ª–∞–≤. –≠–Ω—ç—Ö“Ø“Ø –∫–æ–¥ –Ω—å Streamlit —Å–∞–Ω –∞—à–∏–≥–ª–∞–Ω –≤–µ–± –∏–Ω—Ç–µ—Ä—Ñ—ç–π—Å “Ø“Ø—Å–≥—ç—Ö, ”©–≥”©–≥–¥”©–ª –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö, –±–æ–ª–æ–Ω –º–∞—à–∏–Ω —Å—É—Ä–≥–∞–ª—Ç—ã–Ω –∑–∞–≥–≤–∞—Ä—É—É–¥—ã–≥ —Å—É—Ä–≥–∞—Ö “Ø–π–ª–¥–ª“Ø“Ø–¥–∏–π–≥ –≥“Ø–π—Ü—ç—Ç–≥—ç–Ω—ç.

```python
#| eval: false
#| echo: true
#| code-overflow: wrap
#| label: full-code

# ============================================================
# STREAMLIT TEXT CLASSIFIER DASHBOARD (FINAL + METRICS UI)
# ============================================================

import streamlit as st          # Streamlit ‚Äì –≤–µ–± –¥—ç—ç—Ä dashboard —Ö–∏–π—Ö —Å–∞–Ω
import pandas as pd             # Pandas ‚Äì ”©–≥”©–≥–¥”©–ª –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö —Å–∞–Ω
import numpy as np              # NumPy ‚Äì —Ç–æ–æ—Ü–æ–æ–ª–æ–ª, –º–∞—Ç—Ä–∏—Ü, –º–∞—Å—Å–∏–≤
import re                       # re ‚Äì Regular Expression (—Ç–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç—Ö)

from sklearn.model_selection import train_test_split  # ”®–≥”©–≥–¥”©–ª —Å—É—Ä–≥–∞–ª—Ç/—Ç–µ—Å—Ç—ç–¥ —Ö—É–≤–∞–∞—Ö
from sklearn.pipeline import Pipeline                 # Pipeline ‚Äì –¥–∞—Ä–∞–∞–ª—Å–∞–Ω –∞–ª—Ö–∞–º—É—É–¥ –Ω—ç–≥—Ç–≥—ç—Ö
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer  # –¢–µ–∫—Å—Ç ‚Üí —Ç–æ–æ –±–æ–ª–≥–æ—Ö
from sklearn.naive_bayes import MultinomialNB         # Naive Bayes –∞–Ω–≥–∏–ª–∞–≥—á
from sklearn.linear_model import LogisticRegression    # –õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å –∞–Ω–≥–∏–ª–∞–≥—á
from sklearn.metrics import (                          # –ó–∞–≥–≤–∞—Ä—ã–Ω “Ø–Ω—ç–ª–≥—ç—ç–Ω–∏–π –º–µ—Ç—Ä–∏–∫—É—É–¥
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, roc_auc_score, roc_curve
)

import matplotlib.pyplot as plt          # Matplotlib ‚Äì –≥—Ä–∞—Ñ–∏–∫ –∑—É—Ä–∞—Ö
import seaborn as sns                    # Seaborn ‚Äì –∏–ª“Ø“Ø –≥–æ—ë –≥—Ä–∞—Ñ–∏–∫
from mpl_toolkits.mplot3d import Axes3D  # 3D –≥—Ä–∞—Ñ–∏–∫ “Ø“Ø—Å–≥—ç—Ö
from matplotlib import cm                # ”®–Ω–≥”©–Ω–∏–π —Å—Ö–µ–º
import pandas as pd                      # Pandas –¥–∞—Ö–∏–Ω –∏–º–ø–æ—Ä—Ç–ª–æ–≤–æ–ª –∞—Å—É—É–¥–∞–ª–≥“Ø–π
import plotly.express as px              # Plotly ‚Äì –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ –≥—Ä–∞—Ñ–∏–∫ —Ö–∏–π—Ö

# Streamlit –∞–ø–ø-–∏–π–Ω “Ø–Ω–¥—Å—ç–Ω —Ç–æ—Ö–∏—Ä–≥–æ–æ
st.set_page_config(page_title="Twitter Sentiment Classifier", layout="wide")

# -----------------------------
# Cleaning function
# -----------------------------
def clean_tweet(text):
    text = str(text).lower()                                # –¢–µ–∫—Å—Ç–∏–π–≥ –∂–∏–∂–∏–≥ “Ø—Å—ç–≥ –±–æ–ª–≥–æ—Ö
    text = re.sub(r"http\S+|www\.\S+", "", text)            # URL —É—Å—Ç–≥–∞—Ö
    text = re.sub(r"@\w+", "", text)                        # @username —É—Å—Ç–≥–∞—Ö
    text = re.sub(r"&amp;", "and", text)                    # &amp ‚Üí and –±–æ–ª–≥–æ—Ö
    text = re.sub(r"rt[\s]+", "", text)                     # RT (retweet) —É—Å—Ç–≥–∞—Ö
    text = re.sub(r"[^a-z0-9\s]", " ", text)                # –¢—ç–º–¥—ç–≥—Ç“Ø“Ø–¥–∏–π–≥ –∑–∞–π –±–æ–ª–≥–æ—Ö
    text = re.sub(r"\s+", " ", text).strip()                # –ù—ç–º—ç–ª—Ç –∑–∞–π —Ü—ç–≤—ç—Ä–ª—ç—Ö
    return text                                              # –¶—ç–≤—ç—Ä–ª—ç—Å—ç–Ω —Ç–µ–∫—Å—Ç –±—É—Ü–∞–∞—Ö

# -----------------------------
# Load CSV
# -----------------------------
def load_csv(uploaded_file):
    try:
        df = pd.read_csv(
            uploaded_file,
            encoding="latin-1",                              # Twitter dataset –ª–∞—Ç–∏–Ω –∫–æ–¥–ª–æ–≥–¥–¥–æ–≥
            header=None,                                     # –• –±–∞–≥–∞–Ω—É—É–¥–≥“Ø–π —Ç—É–ª ”©”©—Ä”©”© –Ω—ç—Ä ”©–≥–Ω”©
            names=["target","id","date","flag","user","text"],  # –ë–∞–≥–∞–Ω—É—É–¥—ã–Ω –Ω—ç—Ä
            quoting=1, quotechar='"', escapechar="\\",      # –¢—ç–º–¥—ç–≥—Ç“Ø“Ø–¥–∏–π–≥ –∑”©–≤ —Ç–∞–π–ª–∞—Ö
            engine="python", on_bad_lines="skip"            # –ê–ª–¥–∞–∞—Ç–∞–π –º”©—Ä“Ø“Ø–¥–∏–π–≥ –∞–ª–≥–∞—Å–∞—Ö
        )
        return df
    except Exception as e:
        st.error(f"CSV —É–Ω—à–∏—Ö–∞–¥ –∞–ª–¥–∞–∞: {e}")                  # –•—ç—Ä—ç–≤ –∞–ª–¥–∞–∞ –≥–∞—Ä–≤–∞–ª Streamlit-–¥ —Ö–∞—Ä—É—É–ª–Ω–∞
        return None

# -----------------------------
# Prepare Data
# -----------------------------
def prepare_df(df):
    if "target" not in df.columns or "text" not in df.columns:
        st.error("CSV –Ω—å Twitter dataset —Ö—ç–ª–±—ç—Ä—Ç—ç–π –±–∞–π—Ö —ë—Å—Ç–æ–π.")   # –ê–ª–¥–∞–∞—Ç–∞–π —Ñ–∞–π–ª —à–∞–ª–≥–∞—Ö
        return None
    if set(df["target"].unique()) == {0,4}:                        # 0=negative, 4=positive
        df["target"] = df["target"].map({0:0, 4:1})                # 4 ‚Üí 1 –±–æ–ª–≥–æ–Ω map —Ö–∏–π—Ö
    df["clean_text"] = df["text"].astype(str).apply(clean_tweet)  # –¢–µ–∫—Å—Ç–∏–π–≥ —Ü—ç–≤—ç—Ä–ª—ç–∂ —à–∏–Ω—ç –±–∞–≥–∞–Ω–∞–¥ —Ö–∏–π—Ö
    return df

# -----------------------------
# Build pipelines
# -----------------------------
def build_pipelines():
    nb = Pipeline([
        ("vect", CountVectorizer(max_features=15000, ngram_range=(1,2))),  # 1-2 “Ø–≥–∏–π–Ω –Ω–∏–π–ª–±—ç—Ä ‚Üí —Ç–æ–æ
        ("clf", MultinomialNB())                                           # Naive Bayes classifier
    ])
    lr = Pipeline([
        ("vect", TfidfVectorizer(max_features=20000, ngram_range=(1,2))),   # TF-IDF vectorization
        ("clf", LogisticRegression(max_iter=1000, solver="liblinear"))       # Logistic Regression
    ])
    return {"NaiveBayes": nb, "LogisticRegression": lr}                     # 2 –∑–∞–≥–≤–∞—Ä—ã–≥ dict –±–æ–ª–≥–æ–∂ –±—É—Ü–∞–∞—Ö

# -----------------------------
# Evaluate
# -----------------------------
def evaluate(model, X_test, y_test):
    y_pred = model.predict(X_test)                   # –£—Ä—å–¥—á–∏–ª—Å–∞–Ω —Ç–∞–∞–º–∞–≥
    y_proba = model.predict_proba(X_test)[:,1]       # Positive class-–∏–π–Ω –º–∞–≥–∞–¥–ª–∞–ª
    return {
        "y_pred": y_pred,
        "y_proba": y_proba,
        "acc": accuracy_score(y_test, y_pred),       # Accuracy —Ç–æ–æ—Ü–æ—Ö
        "prec": precision_score(y_test, y_pred),     # Precision
        "rec": recall_score(y_test, y_pred),         # Recall
        "f1": f1_score(y_test, y_pred),              # F1 Score
        "auc": roc_auc_score(y_test, y_proba),       # AUC
        "cm": confusion_matrix(y_test, y_pred),      # Confusion matrix
        "report": classification_report(y_test, y_pred, digits=4)  # –î—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —Ç–∞–π–ª–∞–Ω
    }

# -----------------------------
# Streamlit UI —ç—Ö—ç–ª–∂ –±–∞–π–Ω–∞
# -----------------------------
st.title("üìä Twitter Sentiment Classifier Dashboard")
st.markdown("Upload CSV ‚Üí Train ‚Üí Compare models ‚Üí Posterior + Prediction + Correctness + Metrics")

uploaded_file = st.file_uploader("Upload CSV", type=["csv"])    # CSV upload control
test_size = st.slider("Test size (%)", 10, 50, 30)              # –¢–µ—Å—Ç–∏–π–Ω —Ö—É–≤–∏–π–≥ —Å–æ–Ω–≥–æ—Ö

if uploaded_file:
    df_raw = load_csv(uploaded_file)                             # CSV —Ñ–∞–π–ª—ã–≥ —É–Ω—à–∏—Ö
    if df_raw is not None:
        st.subheader("CSV Preview")
        st.write(df_raw.head())                                  # –≠—Ö–Ω–∏–π 5 –º”©—Ä–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö

        df = prepare_df(df_raw)                                  # –¢–µ–∫—Å—Ç–∏–π–≥ —Ü—ç–≤—ç—Ä–ª—ç—Ö
        if df is not None:
            st.subheader("Dataset Summary")
            st.write(df["target"].value_counts())                # Positive / Negative —Ç–æ–æ

            X = df["clean_text"]                                 # Feature (—Ç–µ–∫—Å—Ç)
            y = df["target"]                                     # Label (0/1)
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size/100, stratify=y, random_state=42
            )

            st.subheader("Training Models...")
            models = build_pipelines()                           # 2 ML model
            results = {}                                         # “Æ—Ä –¥“Ø–Ω —Ö–∞–¥–≥–∞–ª–∞—Ö dict
            bar = st.progress(0)                                 # Progress bar

            # –ó–∞–≥–≤–∞—Ä—É—É–¥—ã–≥ —Å—É—Ä–≥–∞–∂, “Ø–Ω—ç–ª–≥—ç—ç –∞–≤–∞—Ö
            for i, (name, model) in enumerate(models.items(), start=1):
                model.fit(X_train, y_train)                      # –ó–∞–≥–≤–∞—Ä—ã–≥ —Å—É—Ä–≥–∞—Ö –∞–ª–≥–æ—Ä–∏—Ç–º —Ö—ç—Ä—ç–≥–∂“Ø“Ø–ª—ç–ª—Ç
                results[name] = evaluate(model, X_test, y_test)  # “Æ–Ω—ç–ª–≥—ç—ç —Ö–∏–π—Ö
                bar.progress(int(i/len(models)*100))             # –ü—Ä–æ–≥—Ä–µ—Å—Å %

            st.success("‚úÖ Training Done!")  # üîπ –ó–∞–≥–≤–∞—Ä —Å—É—Ä–≥–∞–ª—Ç –±“Ø—Ä—ç–Ω –¥—É—É—Å—Å–∞–Ω—ã–≥ Streamlit –¥—ç—ç—Ä –Ω–æ–≥–æ–æ–Ω –Ω–æ—Ç–æ–ª–≥–æ–æ–≥–æ–æ—Ä —Ö–∞—Ä—É—É–ª–Ω–∞.

            # -----------------------------
            # Model Metrics Overview
            # -----------------------------
            st.subheader("üìå Model Metrics Overview")  # üîπ –•–æ—ë—Ä –∞–Ω–≥–∏–ª–∞–≥—á–∏–π–Ω (NB, LR) –≥–æ–ª “Ø–∑“Ø“Ø–ª—ç–ª—Ç“Ø“Ø–¥–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö –≥–∞—Ä—á–∏–≥
            for name, r in results.items():            # üîπ results dict –¥–æ—Ç–æ—Ä—Ö –±“Ø—Ö –º–æ–¥–µ–ª–∏—É–¥—ã–Ω –Ω—ç—Ä (name) –±–æ–ª–æ–Ω “Ø—Ä –¥“Ø–Ω (r)-–≥ –¥–∞–≤—Ç–∞–ª—Ç–∞–∞—Ä –∞–≤–∞—Ö
                st.markdown(f"### {name}", unsafe_allow_html=True)   # üîπ –ó–∞–≥–≤–∞—Ä—ã–Ω –Ω—ç—Ä–∏–π–≥ —Ç–æ–º –≥–∞—Ä—á–∏–≥ –±–æ–ª–≥–æ–Ω —Ö—ç–≤–ª—ç—Ö

                # 4 metric-–≥ –±–∞–≥–∞–Ω–∞ –±–æ–ª–≥–æ–∂ —Ö–∞—Ä—É—É–ª–∞—Ö
                col1, col2, col3, col4 = st.columns(4)  # üîπ 4 –±–∞–≥–∞–Ω–∞ –±“Ø—Ö–∏–π layout “Ø“Ø—Å–≥—ç—Ö (Accuracy, Precision, Recall, F1-–≥ —Ö–∞–∂—É—É–¥–∞–∞ —Ö–∞—Ä–∞–≥–¥—É—É–ª–Ω–∞)
                col1.metric("Accuracy", f"{r['acc'] * 100:.2f}%")   # üîπ Accuracy-–≥ —Ö—É–≤—å –±–æ–ª–≥–æ–Ω —Ö–∞—Ä—É—É–ª–∞—Ö
                col2.metric("Precision", f"{r['prec'] * 100:.2f}%") # üîπ Precision —Ö—É–≤—å
                col3.metric("Recall", f"{r['rec'] * 100:.2f}%")     # üîπ Recall —Ö—É–≤—å
                col4.metric("F1 Score", f"{r['f1'] * 100:.2f}%")     # üîπ F1-score —Ö—É–≤—å

            # -----------------------------
            # Posterior Table
            # -----------------------------
            st.subheader("Posterior Probability Table (First 10 Tweets)")  # üîπ –≠—Ö–Ω–∏–π 10 ”©–≥”©–≥–¥–ª–∏–π–Ω posterior –º–∞–≥–∞–¥–ª–∞–ª—ã–≥ —Ö“Ø—Å–Ω—ç–≥—Ç—ç—ç—Ä —Ö–∞—Ä—É—É–ª–Ω–∞
            posterior_table = pd.DataFrame({"Tweet": X_test[:10], "True Label": y_test[:10]})
            # üî∏ Test –¥–∞—Ç–∞–∞—Å —ç—Ö–Ω–∏–π 10 –±–∏—á–ª—ç–≥–∏–π–≥ Tweet –±–æ–ª–æ–Ω –∂–∏–Ω—Ö—ç–Ω—ç Label —Ö—ç–ª–±—ç—Ä—ç—ç—Ä –∞–≤—á DataFrame “Ø“Ø—Å–≥—ç–∂ –±–∞–π–Ω–∞

            # Posterior value, Prediction value, Correct —ç—Å—ç—Ö–∏–π–≥ –Ω—ç–º—ç—Ö
            for name, r in results.items():    # üîπ –•–æ—ë—Ä –º–æ–¥–µ–ª–∏—É–¥—ã–Ω “Ø—Ä –¥“Ø–Ω–≥ –¥–∞–≤—Ç–∞–ª—Ç–∞–∞—Ä –∞–≤–∞—Ö
                posterior_table[name+"_Posterior"] = r["y_proba"][:10]   # üîπ Posterior –º–∞–≥–∞–¥–ª–∞–ª—ã–Ω —ç—Ö–Ω–∏–π 10 –±–∏—á–ª—ç–≥–∏–π–≥ –Ω—ç–º—ç—Ö
                posterior_table[name+"_Prediction"] = r["y_pred"][:10]   # üîπ –£—Ä—å–¥—á–∏–ª—Å–∞–Ω –∞–Ω–≥–∏–ª–∞–ª (0 —ç—Å–≤—ç–ª 1)
                posterior_table[name+"_Correct?"] = r["y_pred"][:10] == y_test[:10]  # üîπ –ó”©–≤ —Ç–∞–∞—Å–∞–Ω —ç—Å—ç—Ö–∏–π–≥ Boolean (True/False —Ö—ç–ª–±—ç—Ä—ç—ç—Ä) –Ω—ç–º–Ω—ç

            st.dataframe(posterior_table, height=400)  # üîπ –ë—ç–ª—ç–Ω –±–æ–ª—Å–æ–Ω —Ö“Ø—Å–Ω—ç–≥—Ç–∏–π–≥ Streamlit-–¥ —Ö–∞—Ä—É—É–ª–∞—Ö

            # -----------------------------
            # Interactive Posterior View
            # -----------------------------
            st.subheader("üîé Interactive Posterior + Prediction")  # üîπ –°–æ–Ω–≥–æ—Å–æ–Ω Tweet-–∏–π–Ω posterior-–≥ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ —Ö–∞—Ä–∞—Ö UI –≥–∞—Ä—á–∏–≥
            idx = st.slider("Select Tweet Index", 0, len(X_test)-1, 0)
            # üîπ –•—ç—Ä—ç–≥–ª—ç–≥—á test ”©–≥”©–≥–¥–ª–∏–π–Ω –∏–Ω–¥–µ–∫—Å–∏–π–≥ —Å–æ–Ω–≥–æ—Ö —Å–ª–∞–π–¥–µ—Ä (0-—Å —ç—Ö–ª—ç—ç–¥ —Ö–∞–º–≥–∏–π–Ω —Å“Ø“Ø–ª–∏–π–Ω Tweet —Ö“Ø—Ä—Ç—ç–ª)

            st.write("Tweet:", X_test.iloc[idx])              # üîπ –°–æ–Ω–≥–æ—Å–æ–Ω –∏–Ω–¥–µ–∫—Å–∏–π–Ω Tweet-–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
            st.write("Require True Label:", y_test.iloc[idx]) # üîπ –ó”©–≤ —Ö–∞—Ä–∏—É–≥ —Ö–∞—Ä—É—É–ª–∞—Ö

            # –•–æ—ë—Ä –∑–∞–≥–≤–∞—Ä—ã–Ω posterior-–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
            for name, r in results.items():               # üîπ –ú–æ–¥–µ–ª–∏—É–¥—ã–≥ –¥–∞–≤—Ç–∞–ª—Ç–∞–∞—Ä —à–∞–ª–≥–∞—Ö
                posterior = r["y_proba"][idx]            # üîπ –°–æ–Ω–≥–æ—Å–æ–Ω –∏–Ω–¥–µ–∫—Å–∏–π–Ω posterior probability
                pred = r["y_pred"][idx]                  # üîπ –°–æ–Ω–≥–æ—Å–æ–Ω –∏–Ω–¥–µ–∫—Å–∏–π–Ω prediction (0/1)
                correct = "‚úÖ True" if pred == y_test.iloc[idx] else "‚ùå False"
                # üîπ Prediction –∑”©–≤ —ç—Å—ç—Ö–∏–π–≥ —Ç—ç–º–¥—ç–≥–ª—ç–≥—ç—ç—Ç—ç–π —Ö–∞—Ä—É—É–ª–Ω–∞

                st.metric(label=f"{name} Posterior (+ probability)", value=f"{posterior * 100:.2f}%")
                # üîπ Posterior probability-–≥ —Ö—É–≤—å —Ö—ç–ª–±—ç—Ä—ç—ç—Ä —Ö–∞—Ä—É—É–ª–∞—Ö
                st.write(f"{name} Prediction:", pred, "| Correct?", correct)
                # üîπ Prediction –±–æ–ª–æ–Ω –∑”©–≤ —ç—Å—ç—Ö

            # -----------------------------
            # Confusion matrices
            # -----------------------------
            st.subheader("üîé Confusion Matrices (T/F row & column labels)")
            # üîπ –ó–∞–≥–≤–∞—Ä —Ç—É—Å –±“Ø—Ä–∏–π–Ω —Ö“Ø—Ä—ç—ç –º–∞—Ç—Ä–∏—Ü (Confusion Matrix)‚Äì–≥ —Ö–∞—Ä—É—É–ª–∞—Ö

            cols = st.columns(len(results))  # üîπ –ú–æ–¥–µ–ª–∏—É–¥—ã–Ω —Ç–æ–æ—Ç–æ–π —Ç—ç–Ω—Ü“Ø“Ø —Ö—ç–º–∂—ç—ç—Ç—ç–π –±–∞–≥–∞–Ω—ã–≥ UI-–¥ “Ø“Ø—Å–≥—ç–Ω—ç (2 model ‚Üí 2 column)

            for col, (name, r) in zip(cols, results.items()):  # üîπ –ë–∞–≥–∞–Ω–∞ –±“Ø—Ä—Ç –Ω—ç–≥ –∑–∞–≥–≤–∞—Ä –±–∞–π—Ä–ª—É—É–ª–Ω–∞
                with col:
                    st.markdown(f"### {name}")  # üîπ –ó–∞–≥–≤–∞—Ä—ã–Ω –Ω—ç—Ä

                    cm_vals = r["cm"]           # üîπ Confusion matrix —É—Ç–≥—É—É–¥—ã–≥ –∞–≤—á –±–∞–π–Ω–∞

                    fig, ax = plt.subplots(figsize=(5, 4))  # üîπ Heatmap –∑—É—Ä–∞—Ö —à–∏–Ω—ç Figure “Ø“Ø—Å–≥—ç–Ω—ç
                    sns.heatmap(
                        cm_vals,                # üîπ Confusion matrix-–∏–π–Ω —Ç–æ–æ–Ω ”©–≥”©–≥–¥”©–ª
                        annot=True,             # üîπ –¢–æ–æ–Ω—É—É–¥—ã–≥ –¥–æ—Ç—Ä–æ–æ —Ö–∞—Ä—É—É–ª–Ω–∞
                        fmt="d",                # üîπ –¢–æ–æ–Ω—É—É–¥—ã–≥ integer —Ö—ç–ª–±—ç—Ä—ç—ç—Ä —Ö–∞—Ä—É—É–ª–∞—Ö
                        cmap="YlGnBu",          # üîπ ”®–Ω–≥”©–Ω–∏–π —Å—Ö–µ–º
                        ax=ax,                  # üîπ –•–∞–∞–Ω–∞ –∑—É—Ä–∞—Ö—ã–≥ –∑–∞–∞–∂ ”©–≥—á –±–∞–π–Ω–∞
                        annot_kws={"size":12, "weight":"bold"}, # üîπ –ê–Ω–Ω–æ—Ç–∞—Ü–∏–π–Ω —Ñ–æ–Ω—Ç—ã–Ω —Å—Ç–∏–ª—å
                        linewidths=1,           # üîπ –•–∏–ª —à—É–≥–∞–º—ã–Ω ”©—Ä–≥”©–Ω
                        linecolor="white",      # üîπ –•–∏–ª —à—É–≥–∞–º—ã–Ω ”©–Ω–≥”©
                        cbar=True               # üîπ Color bar —Ö–∞—Ä—É—É–ª–∞—Ö —ç—Å—ç—Ö
                    )

                    ax.set_yticklabels(['T','F'], rotation=0)  # üîπ Y —Ç—ç–Ω—Ö–ª—ç–≥–∏–π–Ω (Actual) —Ç—ç–º–¥—ç–≥–ª—ç–≥—ç—ç: T=True, F=False
                    ax.set_xticklabels(['F','T'], rotation=0)  # üîπ X —Ç—ç–Ω—Ö–ª—ç–≥–∏–π–Ω (Predicted) —Ç—ç–º–¥—ç–≥–ª—ç–≥—ç—ç

                    ax.set_xlabel("Predicted")                 # üîπ X —Ç—ç–Ω—Ö–ª—ç–≥–∏–π–Ω –Ω—ç—Ä
                    ax.set_ylabel("Actual")                   # üîπ Y —Ç—ç–Ω—Ö–ª—ç–≥–∏–π–Ω –Ω—ç—Ä
                    ax.set_title(f"{name} Confusion Matrix (T/F)")  # üîπ –ì—Ä–∞—Ñ–∏–∫–∏–π–Ω –≥–∞—Ä—á–∏–≥

                    st.pyplot(fig, use_container_width=True)  # üîπ Streamlit-–¥ –≥—Ä–∞—Ñ–∏–∫–∏–π–≥ —Ö—ç–≤–ª—ç—Ö

            # -----------------------------
            # 3D Posterior Histogram
            # -----------------------------
            st.subheader("üîéPosterior Probability Distribution (3D View)")
            # üîπ Posterior –º–∞–≥–∞–¥–ª–∞–ª—ã–Ω —Ç–∞—Ä—Ö–∞–ª—Ç—ã–≥ 3D –±–∞–≥–∞–Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∞–∞—Ä —Ö–∞—Ä—É—É–ª–∞—Ö (–∑–∞–≥–≤–∞—Ä —Ç—É—Å –±“Ø—Ä—Ç)

            cols = st.columns(len(results))  # üîπ –ú–æ–¥–µ–ª–∏—É–¥—ã–Ω —Ç–æ–æ—Ç–æ–π —Ç—ç–Ω—Ü—ç—Ö –±–∞–≥–∞–Ω–∞

            for col, (name, r) in zip(cols, results.items()):
                with col:
                    fig = plt.figure(figsize=(5,4))                 # üîπ –®–∏–Ω—ç Figure “Ø“Ø—Å–≥—ç–Ω—ç
                    ax = fig.add_subplot(111, projection='3d')      # üîπ 3D subplot “Ø“Ø—Å–≥—ç–Ω—ç

                    hist, bins = np.histogram(r["y_proba"], bins=25)  # üîπ Posterior probability-–≥ histogram –±–æ–ª–≥–æ—Ö
                    xpos = (bins[:-1] + bins[1:]) / 2                # üîπ –ë–∞–≥–∞–Ω—É—É–¥—ã–Ω X –±–∞–π—Ä–ª–∞–ª
                    ypos = np.zeros_like(xpos)                       # üîπ Y –±–∞–π—Ä–ª–∞–ª –±“Ø–≥–¥ 0 (3D –±–∞—Ä-–Ω–¥ dummy)
                    zpos = np.zeros_like(xpos)                       # üîπ –ë–∞–≥–∞–Ω–∞ Z —ç—Ö–ª—ç–ª 0
                    dx = (bins[1]-bins[0]) * np.ones_like(xpos)      # üîπ –ë–∞–≥–∞–Ω—É—É–¥—ã–Ω ”©—Ä–≥”©–Ω (X)
                    dy = np.ones_like(xpos)                          # üîπ Y –∑—É–∑–∞–∞–Ω
                    dz = hist                                        # üîπ –ë–∞–≥–∞–Ω—É—É–¥—ã–Ω ”©–Ω–¥”©—Ä

                    colors = cm.viridis(dz / dz.max())               # üîπ Histogram ”©–Ω–¥”©—Ä—Ç —Å—É—É—Ä–∏–ª—Å–∞–Ω ”©–Ω–≥”©

                    ax.bar3d(xpos, ypos, zpos, dx, dy, dz, color=colors, edgecolor='k')
                    # üîπ 3D –±–∞—Ä –≥—Ä–∞—Ñ–∏–∫ –∑—É—Ä–∂ –±–∞–π–Ω–∞

                    ax.set_xlabel('Posterior Probability')  # üîπ X —Ç—ç–Ω—Ö–ª—ç–≥–∏–π–Ω –Ω—ç—Ä
                    ax.set_ylabel('Y (dummy)')              # üîπ Dummy Y —Ç—ç–Ω—Ö–ª—ç–≥
                    ax.set_zlabel('Frequency')              # üîπ Frequency –±—É—é—É –¥–∞–≤—Ç–∞–º–∂
                    ax.set_title(f"{name} Posterior Probability (3D)")  # üîπ –ì–∞—Ä—á–∏–≥

                    ax.view_init(elev=30, azim=-60)  # üîπ –ö–∞–º–µ—Ä—ã–Ω —Ö–∞—Ä–∞—Ö ”©–Ω—Ü”©–≥ —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö

                    st.pyplot(fig, use_container_width=True)  # üîπ Streamlit-–¥ —Ö—ç–≤–ª—ç—Ö

            # -----------------------------
            # Scatter Plots
            # -----------------------------
            st.subheader("Interactive Scatter Plots: Posterior Comparison & Correctness")
            # üîπ NB –±–∞ LR —Ö–æ—ë—Ä—ã–Ω posterior-–≥ —Ö–æ–æ—Ä–æ–Ω–¥ –Ω—å —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ Plotly –≥—Ä–∞—Ñ–∏–∫

            df_scatter = pd.DataFrame({
                "NB_Proba": results["NaiveBayes"]["y_proba"],            # üîπ NB posterior probability
                "LR_Proba": results["LogisticRegression"]["y_proba"],    # üîπ LR posterior probability
                "True_Label": y_test.values,                             # üîπ –ñ–∏–Ω—Ö—ç–Ω—ç Label
                "Tweet": X_test.values,                                  # üîπ Tweet —Ç–µ–∫—Å—Ç
                "NB_Correct": results["NaiveBayes"]["y_pred"] == y_test, # üîπ NB –∑”©–≤ —Ç–∞–∞—Å–∞–Ω —ç—Å—ç—Ö
                "LR_Correct": results["LogisticRegression"]["y_pred"] == y_test # üîπ LR –∑”©–≤ —Ç–∞–∞—Å–∞–Ω —ç—Å—ç—Ö
            })

            cols = st.columns(2)  # üîπ 2 –≥—Ä–∞—Ñ–∏–∫–∏–π–≥ –∑—ç—Ä—ç–≥—Ü“Ø“Ø–ª—ç–Ω —Ö–∞—Ä–∞–≥–¥—É—É–ª–∞—Ö —Ö–æ—ë—Ä –±–∞–≥–∞–Ω–∞

            # Posterior comparison chart
            with cols[0]:
                fig1 = px.scatter(
                    df_scatter,
                    x="NB_Proba",     # üîπ NB posterior probability X —Ç—ç–Ω—Ö–ª—ç–≥
                    y="LR_Proba",     # üîπ LR posterior probability Y —Ç—ç–Ω—Ö–ª—ç–≥
                    color="True_Label",   # üîπ –ñ–∏–Ω—Ö—ç–Ω—ç Label-–∏–π–≥ ”©–Ω–≥”©”©—Ä —è–ª–≥–∞–Ω–∞
                    hover_data={"Tweet": True},   # üîπ Mouse-–≥ tweet –¥—ç—ç—Ä –∞–≤—á—Ä–∞—Ö–∞–¥ —Ö–∞—Ä—É—É–ª–∞—Ö —Ç–µ–∫—Å—Ç
                    title="Posterior Probability Comparison"  # üîπ –ì–∞—Ä—á–∏–≥
                )
                st.plotly_chart(fig1, use_container_width=True)  # üîπ Streamlit-–¥ —Ö—ç–≤–ª—ç—Ö

            # Correctness comparison chart
            with cols[1]:
                df_scatter["Both_Correct"] = df_scatter["NB_Correct"] & df_scatter["LR_Correct"]
                # üîπ –•–æ—ë—Ä –∑–∞–≥–≤–∞—Ä —Ö–æ—ë—É–ª–∞–∞ –∑”©–≤ –±–∞–π—Å–∞–Ω —ç—Å—ç—Ö–∏–π–≥ —Ç–æ–æ—Ü–æ—Ö

                fig2 = px.scatter(
                    df_scatter,
                    x="NB_Proba",         # üîπ NB posterior
                    y="LR_Proba",         # üîπ LR posterior
                    color="Both_Correct", # üîπ –•—ç—Ä–≤—ç—ç NB –±–æ–ª–æ–Ω LR —Ö–æ—ë—É–ª–∞–∞ –∑”©–≤ ‚Üí True, “Ø–≥“Ø–π –±–æ–ª False
                    hover_data={"Tweet": True},  # üîπ Tweet —Ç–µ–∫—Å—Ç —Ö–∞—Ä—É—É–ª–∞—Ö
                    title="Correct vs Incorrect Predictions"  # üîπ –ì—Ä–∞—Ñ–∏–∫–∏–π–Ω –Ω—ç—Ä
                )
                st.plotly_chart(fig2, use_container_width=True)  # üîπ Streamlit-–¥ –≥—Ä–∞—Ñ–∏–∫–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö

        else:
                st.info("‚è≥ Upload CSV to train and see posterior probability, prediction, correctness, and metrics.")
                # üîπ –•—ç—Ä–≤—ç—ç CSV upload —Ö–∏–π–≥–¥—ç—ç–≥“Ø–π –±–æ–ª –º—ç–¥—ç—ç–ª–ª–∏–π–Ω –º–µ—Å—Å–µ–∂ —Ö–∞—Ä—É—É–ª–∞—Ö
```
