---
title: "Текстэн мэдээллийн сэтгэл хөдлөлийг статистик аргаар ангилах нь: Гэнэн Байес болон Ложистик регрессийн харьцуулсан шинжилгээ"
subtitle: "Машин сургалтын төсөл"
abstract: Энэхүү төслийн хүрээнд нийгмийн сүлжээний "Sentiment140" өгөгдөл дээр хяналттай машин сургалтын (Supervised Learning) аргуудыг ашиглан хэрэглэгчийн сэтгэл хөдлөлийг эерэг болон сөрөг гэж ангилав. Бид өгөгдлийн түүвэр дээр Гэнэн Байесын (Naive Bayes) аргаар постериор магадлалыг тооцоолох болон Ложистик регрессийн (Logistic Regression) ложит загварыг харьцуулан туршив. Судалгааны үр дүнд Ложистик регресс загвар нь [X]%-ийн нарийвчлалтайгаар текстийн утгыг зөв таньж, харьцуулсан загвараас илүү оновчтой үр дүн үзүүлсэн байна.
author: "Л.Анужин, Г.Батням, Э.Мэндбаяр, Б.Хувьзаяа, А.Эрхэс"
date: 2025-11-28
date-format: "YYYY оны M-р сарын D"
project:
  execute-dir: project
  preview: false
toc: true
toc-depth: 3
toc-title: Агуулга
number-sections: true
format:
  pdf:
    echo: true
    pdf-engine: xelatex
    papersize: a4paper
    geometry:
      - left=2cm
      - right=2cm
      - top=2cm
      - bottom=3cm
    include-in-header:
      - text: |
          \usepackage[english,mongolian]{babel}
          \usepackage{fontspec}
          % үндсэн текстийн шрифт
          \setmainfont{Times New Roman}
          % код хэсгийн шрифт
          \setmonofont{DejaVu Sans Mono}
          \AddToHook{env/Highlighting/begin}{\footnotesize}
          % үндсэн гарчиг
          \usepackage{titling}
          \pretitle{\begin{center}\LARGE\bfseries}
          \posttitle{\par\end{center}\vskip 1em}
          % сэдвийн зүйлчлэл хэсгийн шрифт
          \usepackage{titlesec}
          \titleformat{\section}{\normalfont\Large\bfseries\selectfont}{\thesection}{1em}{}
          \titleformat{\subsection}{\normalfont\large\bfseries\selectfont}{\thesubsection}{1em}{}
          \titleformat{\subsubsection}{\normalfont\normalsize\bfseries\selectfont}{\thesubsubsection}{1em}{}
          % сэдвийн жагсаалт доторх шрифт
          \usepackage{tocloft}
          \renewcommand{\cfttoctitlefont}{\Large\bfseries\fontspec{Times New Roman}}
          \renewcommand{\cftaftertoctitle}{\vskip 1em}
          \renewcommand{\cftsecfont}{\normalfont\selectfont}
          \renewcommand{\cftsecpagefont}{\normalfont\selectfont}
          \renewcommand{\cftsubsecfont}{\normalfont\selectfont}
          \renewcommand{\cftsubsecpagefont}{\normalfont\selectfont}
          \renewcommand{\contentsname}{Агуулга}
    latex-max-runs: 3
editor: source
execute:
  echo: false
crossref: 
  fig-title: Зураг
  fig-prefix: Зураг
  tbl-title: Хүснэгт
  tbl-prefix: Хүснэгт
fig-align: center
fig-env: "figure"
fig-height: 4
fig-width: 6
fig-pos: "!ht"
fig-format: pdf
fig-cap-location: top
tbl-cap-location: top
bibliography: references.bib
csl: ieee.csl
citeproc: true
link-citations: true
---

```{python}
#| echo: false
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Дүгнэлт хадгалах жагсаалт
conclusion = list()
```


# Шаардлагатай багцууд {-}
Шаардлагатай багцуудыг дараах байдлаар урьдчилан суулгана.

`pip install streamlit pandas numpy scikit-learn matplotlib seaborn plotly`

# Удиртгал

Нийгмийн сүлжээ, тэр дундаа Twitter (одоогийн X) платформ нь олон нийтийн санаа бодол, хандлагыг илэрхийлэх томоохон эх сурвалж юм. Хэрэглэгчид өөрсдийн үзэл бодлоо богино хэмжээний текст буюу "жиргээ" (tweet) хэлбэрээр илэрхийлдэг. Эдгээр их хэмжээний өгөгдөлд дүн шинжилгээ хийх нь бизнесийн байгууллага болон судлаачдад хэрэглэгчийн сэтгэл ханамжийг үнэлэхэд чухал ач холбогдолтой боловч сая сая жиргээг хүний оролцоотойгоор уншиж ангилах боломжгүй юм.

Иймд энэхүү төслийн ажлаар бид Стэнфордын их сургуулийн судлаачдын боловсруулсан **Sentiment140** өгөгдлийн санд тулгуурлан, сэтгэл хөдлөлийг автоматаар таньж, эерэг болон сөрөг гэж ангилах статистик загварыг хөгжүүлэв. Судалгаанд **Гэнэн Байесын алгоритм** (Naive Bayes) болон **Ложистик регресс** (Logistic Regression) гэсэн хоёр өөр статистик аргыг ашиглаж, тэдгээрийн үр дүнг харьцуулан шинжиллээ.

# Өгөгдөл ба Боловсруулалт

## Өгөгдлийн эх сурвалж ба бүтэц

Энэхүү судалгаанд бид Alec Go, Richa Bhayani, Lei Huang нарын (2009) цуглуулсан **Sentiment140** @sentiment140 өгөгдлийн санг ашиглав. Уг өгөгдлийн сан нь Twitter API ашиглан цуглуулсан 1.6 сая жиргээнээс бүрдэнэ. Өгөгдлийн хаягжуулалт (Labeling) нь "Зайнаас хяналттай сургалт" (Distant Supervision) аргаар хийгдсэн. Тодруулбал:

* Сэтгэл хөдлөл илэрхийлсэн тэмдэгт `:)` агуулсан жиргээг **"Эерэг" (4)**,
* `:( ` тэмдэгт агуулсан жиргээг **"Сөрөг" (0)** гэж автоматаар ангилсан.

Сургалтын явцад загвар зөвхөн тэмдэгтийг цээжлэхээс сэргийлж, жиргээний текстээс эдгээр тэмдэгтүүдийг (emoticons) устгасан байдаг. Бидний ашигласан өгөгдлийн бүтэц дараах байдалтай байна:

```{python}
#| echo: false
#| label: tbl-data-preview
#| tbl-cap: Өгөгдлийн бүтцийн жишээ (sample_set.csv)

import pandas as pd
from IPython.display import Markdown

# 1. Read the local file
df_sample = pd.read_csv("sample_set.csv")

# 2. Select columns want to show
subset = df_sample[["target", "text"]].sample(n=5, random_state=1).copy()

# 3. Rename columns for the Mongolian Report
subset.columns = ["Ангилал (Target)", "Жиргээ (Text)"]

# 4. Truncate text
subset["Жиргээ (Text)"] = subset["Жиргээ (Text)"].astype(str).str.slice(0,70) + "..."

# 5. Print
Markdown(subset.to_markdown(index=False))
```

## Өгөгдлийн түүвэрлэлт (Sampling)

Sentiment140 өгөгдлийн сан нь нийт 1.6 сая мөр бүхий их хэмжээний өгөгдлийг агуулдаг. Энэхүү төслийн хүрээнд тооцооллын нөөц болон хугацааг хэмнэх зорилгоор бид "Санамсаргүй түүвэрлэлт" (Simple Random Sampling)-ийн аргыг ашиглав.

Бид Python хэлний `sample()` функцийг ашиглан нийт өгөгдлөөс **50,000** жиргээг санамсаргүй байдлаар сонгон авч сургалтад ашигласан. Туршилтын үр дүн дахин давтагдах (reproducible) боломжтой байхын тулд `random_state=42` тохиргоог ашигласан болно.

```{python}
#| echo: true
#| eval: false

# Бүтэн өгөгдлийг унших (1.6 сая мөр)
df_full = pd.read_csv("training.1600000.processed.noemoticon.csv", 
                      encoding="latin-1", header=None)

# 50,000 мөрийг санамсаргүйгээр түүвэрлэх (Seed = 42)
df = df_full.sample(n=50000, random_state=42)
```

## Өгөгдлийг цэвэрлэх ба Бэлтгэх (Preprocessing)

Түүхий өгөгдөл (Raw Data) нь дүн шинжилгээ хийхэд саад болох олон төрлийн "шуугиан" (noise) агуулдаг. Таны багийн бичсэн кодын дагуу бид Python хэлний `re` (Regular Expression) санг ашиглан текстэн өгөгдлийг дараах байдлаар цэвэрлэлээ.

1.  Жижиг үсэгт шилжүүлэх: `lower()` функц ашиглан бүх текстийг жижиг үсэг болгов.
2.  URL болон Хэрэглэгчийн нэр: `http` болон `@username` хэлбэрийн холбоосуудыг устгав.
3.  HTML тэмдэгт: `&amp;` гэх мэт кодыг `and` гэх мэт энгийн үгээр солив.
4.  RT (Retweet): Жиргээг дамжуулсан тэмдэглэгээг хасав.
5.  Тусгай тэмдэгт: Үсэг болон тооноос бусад тэмдэгтүүдийг устгав.

```{python}
#| echo: true

import re

def clean_tweet(text):
    text = str(text).lower()                                # Жижиг үсэг болгох
    text = re.sub(r"http\S+|www\.\S+", "", text)            # URL устгах
    text = re.sub(r"@\w+", "", text)                        # @username устгах
    text = re.sub(r"&amp;", "and", text)                    # &amp → and болгох
    text = re.sub(r"rt[\s]+", "", text)                     # RT (retweet) устгах
    text = re.sub(r"[^a-z0-9\s]", " ", text)                # Тусгай тэмдэгт устгах
    text = re.sub(r"\s+", " ", text).strip()                # Илүүдэл зай цэвэрлэх
    return text

# Өгөгдлийг цэвэрлэх (Жишээ өгөгдөл дээр)
df_sample["clean_text"] = df_sample["text"].astype(str).apply(clean_tweet)

# Target хувьсагчийг 0 (Сөрөг) ба 1 (Эерэг) болгож хөрвүүлэх
# (Sentiment140 өгөгдөлд 4 нь Эерэг байдаг)
if set(df_sample["target"].unique()) == {0, 4}:
    df_sample["target"] = df_sample["target"].map({0: 0, 4: 1})
```

Цэвэрлэгээ хийсний дараах үр дүнг доорх хүснэгтэд харуулав.

```{python}
#| echo: false
#| label: tbl-clean-preview
#| tbl-cap: Цэвэрлэсэн өгөгдлийн жишээ

from IPython.display import Markdown

# Харуулах багануудаа сонгох
subset_clean = df_sample[["target", "text", "clean_text"]].sample(n=5, random_state=1).copy()
subset_clean.columns = ["Ангилал", "Эх текст", "Цэвэр текст"]

# Урт текстийг тайрах (PDF дээр багтаахын тулд)
subset_clean["Эх текст"] = subset_clean["Эх текст"].str.slice(0, 40) + "..."
subset_clean["Цэвэр текст"] = subset_clean["Цэвэр текст"].str.slice(0, 40) + "..."

Markdown(subset_clean.to_markdown(index=False))
```

## Өгөгдлийн шинжилгээ (EDA)
Сургалтад ашиглаж буй өгөгдлийн тэнцвэртэй байдлыг шалгах нь чухал юм. Бидний ашиглаж буй түүвэр өгөгдөлд Сөрөг (0) болон Эерэг (1) ангилал хэрхэн тархсаныг доорх диаграммаар харуулав.

```{python}
#| warning: false
#| label: fig-countplot
#| fig-cap: Сэтгэл хөдлөлийн ангиллын тархалт

import matplotlib.pyplot as plt
import seaborn as sns

# Графикийн хэмжээг тохируулах
plt.figure(figsize=(6, 3))

# Countplot зурах
sns.countplot(x=df_sample["target"], palette="viridis")

# Тэнхлэгийн нэрс
plt.xticks([0, 1], ["Сөрөг (0)", "Эерэг (1)"])
plt.xlabel("Сэтгэл хөдлөл")
plt.ylabel("Жиргээний тоо")
plt.title("Өгөгдлийн тэнцвэртэй байдал")
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()
```

Диаграммаас харахад өгөгдөл тэнцвэртэй байгаа нь загвар аль нэг тал руу хэт хазайх (bias) эрсдэлгүйг харуулж байна.

# Судалгааны арга зүй

Энэхүү судалгаанд бид текстэн мэдээллийг ангилахдаа **хяналттай машин сургалтын** (Supervised Machine Learning) түгээмэл аргууд болох **Гэнэн Байес** болон **Ложистик регресс** загваруудыг ашиглав.

## Векторжуулах арга (Feature Extraction)

Машин сургалтын загварууд нь текстийг шууд ойлгох боломжгүй тул бид тэдгээрийг тоон хэлбэрт шилжүүлэх шаардлагатай. Үүнд дараах хоёр аргыг ашиглав:

1.  **CountVectorizer (Bag of Words):** Үгсийн давтамжийг тоолох энгийн арга.
2.  **TF-IDF (Term Frequency-Inverse Document Frequency):** Үгсийн давтамжийг нийт баримт бичигт эзлэх хувиар жинлэн үнэлэх арга.

## Гэнэн Байесын алгоритм (Naive Bayes)

Энэ нь Байесын зарчимд суурилсан ангиллын алгоритм юм. Лекц XVI (хуудас 147)-д дурдсанаар юмс үзэгдлийг хамгийн их **постериор магадлалтай** ангид хуваарилдаг:

$$ \operatorname{argmax}_{k} P(C_k) \prod_{i=1}^{n} P(X_i|C_k) $$

Энд:

*   $P(C_k)$: Приор магадлал (Тухайн ангиллын ерөнхий магадлал).
*   $P(X_i|C_k)$: Үнэний хувь (Likelihood) буюу тухайн ангилалд $X_i$ шинж чанар (үг) илрэх магадлал.
*   $\prod$: Үржвэр (Бүх үгсийн магадлалыг хооронд нь үржүүлж байна).

Бид энэхүү төсөлд `MultinomialNB` хувилбарыг ашигласан.

## Ложистик регресс (Logistic Regression)

Ложистик регресс нь үр дүнг 0-ээс 1-ийн хооронд магадлалаар илэрхийлдэг. Лекц XVI (хуудас 144)-д дурдсанаар энэ нь шугаман регрессийн утгыг **ложистик функц** ашиглан хувиргадаг:

$$ p = \frac{e^{a+bX}}{1 + e^{a+bX}} $$

Энд:

*   $p$: Жиргээ эерэг байх магадлал.
*   $a+bX$: Текстэн өгөгдлийн шинж чанаруудын шугаман хослол.
*   $e$: Натурын логарифмын суурь.

Энэ арга нь хувьсагчдын нарийн хамаарлыг илрүүлэхдээ сайн ажилладаг бөгөөд үр дүнг магадлалаар илэрхийлдэг давуу талтай.

# Туршилт ба Үр дүн

Бид боловсруулсан 50,000 мөр өгөгдлийг сургалтын (Training set) болон тестийн (Test set) олонлогт **70:30** харьцаатайгаар санамсаргүйгээр хуваасан. Ингэхдээ ангиллын тэнцвэртэй байдлыг хадгалахын тулд `stratify` параметрийг ашиглав.

```{python}
#| echo: true
#| warning: false

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Өгөгдлийг бэлтгэх (Өмнөх хэсэгт цэвэрлэсэн df_sample-г ашиглана)
# clean_text баганад NaN байхгүй эсэхийг шалгаад string болгох
X = df_sample["clean_text"].fillna("").astype(str)
y = df_sample["target"]

# 70% сургалт, 30% тест
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# 1. Гэнэн Байес (Naive Bayes) Pipeline
nb_model = Pipeline([
    ("vect", CountVectorizer(max_features=15000, ngram_range=(1,2))),
    ("clf", MultinomialNB())
])

# 2. Ложистик Регресс (Logistic Regression) Pipeline
lr_model = Pipeline([
    ("vect", TfidfVectorizer(max_features=20000, ngram_range=(1,2))),
    ("clf", LogisticRegression(max_iter=1000, solver="liblinear"))
])

# Загваруудыг сургах
nb_model.fit(X_train, y_train)
lr_model.fit(X_train, y_train)

# Таамаглал дэвшүүлэх
y_pred_nb = nb_model.predict(X_test)
y_pred_lr = lr_model.predict(X_test)

# Нарийвчлал тооцох
acc_nb = accuracy_score(y_test, y_pred_nb)
acc_lr = accuracy_score(y_test, y_pred_lr)
```

## Загваруудын харьцуулалт

Туршилтын үр дүнд хоёр загварын нарийвчлал (Accuracy) дараах байдалтай гарав. Бидний таамаглаж байснаар Ложистик регресс загвар нь илүү өндөр үр дүн үзүүллээ.

| Загвар | Нарийвчлал (Accuracy) | Тайлбар |
| :--- | :--- | :--- |
| **Гэнэн Байес** | `{python} f"{acc_nb*100:.2f}%"` | Хурдан ажилладаг боловч үгсийн хамаарлыг тооцдоггүй. |
| **Ложистик Регресс** | `{python} f"{acc_lr*100:.2f}%"` | TF-IDF жинлэлт ашигласан тул илүү нарийвчлалтай. |

: Загваруудын нарийвчлалын харьцуулалт {#tbl-accuracy}

## Төөрөгдлийн матриц (Confusion Matrix)

Загвар хэрхэн ажилласныг илүү нарийвчлан харахын тулд өндөр үр дүн үзүүлсэн Ложистик Регресс загварын Төөрөгдлийн матрицыг байгуулъя. Энэ нь загвар "Сөрөг" болон "Эерэг" жиргээг хэр зөв ялгаж байгааг харуулна.

```{python}
#| label: fig-confusion-matrix
#| fig-cap: Ложистик Регресс загварын Төөрөгдлийн матриц
#| warning: false
#| echo: true

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Матриц тооцоолох
cm = confusion_matrix(y_test, y_pred_lr)

# График зурах
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", 
            xticklabels=["Сөрөг (Pred)", "Эерэг (Pred)"],
            yticklabels=["Сөрөг (True)", "Эерэг (True)"])
plt.title("Logistic Regression Confusion Matrix")
plt.show()
```

```{python}
#| echo: false
# Дүгнэлт хэсэгт ашиглах хувьсагчид (Автоматаар бөглөгдөнө)
conclusion.append(f"Санамсаргүй түүвэрлэсэн {len(df_sample)} өгөгдөл дээр туршилт хийхэд Ложистик Регресс загвар {acc_lr*100:.1f}% нарийвчлалтай байв.")
conclusion.append(f"Гэнэн Байес загвар ({acc_nb*100:.1f}%) нь хурдан боловч нарийвчлалаар бага зэрэг дутмаг байв.")
conclusion.append("Ложит загвар болон TF-IDF векторжуулалт нь сэтгэл хөдлөлийг ангилахад илүү тохиромжтой арга болох нь батлагдлаа.")
```

# Дүгнэлт {.unnumbered}

# Багийн гишүүдийн оролцоо {.unnumbered}

# Ашигласан материал {.unnumbered}

# Хавсралт: Програмын код {.unnumbered}

::: {#refs}
:::
