
import streamlit as st          # Streamlit ‚Äì –≤–µ–± –¥—ç—ç—Ä dashboard —Ö–∏–π—Ö —Å–∞–Ω
import pandas as pd             # Pandas ‚Äì ”©–≥”©–≥–¥”©–ª –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö —Å–∞–Ω
import numpy as np              # NumPy ‚Äì —Ç–æ–æ—Ü–æ–æ–ª–æ–ª, –º–∞—Ç—Ä–∏—Ü, –º–∞—Å—Å–∏–≤
import re                       # re ‚Äì Regular Expression (—Ç–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç—Ö)

from sklearn.model_selection import train_test_split  # ”®–≥”©–≥–¥”©–ª —Å—É—Ä–≥–∞–ª—Ç/—Ç–µ—Å—Ç—ç–¥ —Ö—É–≤–∞–∞—Ö
from sklearn.pipeline import Pipeline                 # Pipeline ‚Äì –¥–∞—Ä–∞–∞–ª—Å–∞–Ω –∞–ª—Ö–∞–º—É—É–¥ –Ω—ç–≥—Ç–≥—ç—Ö
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer  # –¢–µ–∫—Å—Ç ‚Üí —Ç–æ–æ –±–æ–ª–≥–æ—Ö
from sklearn.naive_bayes import MultinomialNB         # Naive Bayes –∞–Ω–≥–∏–ª–∞–≥—á
from sklearn.linear_model import LogisticRegression    # –õ–æ–∂–∏—Å—Ç–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å –∞–Ω–≥–∏–ª–∞–≥—á
from sklearn.metrics import (                          # –ó–∞–≥–≤–∞—Ä—ã–Ω “Ø–Ω—ç–ª–≥—ç—ç–Ω–∏–π –º–µ—Ç—Ä–∏–∫—É—É–¥ –∂–∏—à—ç—ç –Ω—å:accuracy, precision, recall, f1-score
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, roc_auc_score, roc_curve
)

import matplotlib.pyplot as plt          # Matplotlib ‚Äì –≥—Ä–∞—Ñ–∏–∫ –∑—É—Ä–∞—Ö
import seaborn as sns                    # Seaborn ‚Äì –∏–ª“Ø“Ø –≥–æ—ë –≥—Ä–∞—Ñ–∏–∫
from mpl_toolkits.mplot3d import Axes3D  # 3D –≥—Ä–∞—Ñ–∏–∫ “Ø“Ø—Å–≥—ç—Ö
from matplotlib import cm                # ”®–Ω–≥”©–Ω–∏–π —Å—Ö–µ–º
import pandas as pd                      # Pandas
import plotly.express as px              # Plotly ‚Äì –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ –≥—Ä–∞—Ñ–∏–∫ —Ö–∏–π—Ö

# Streamlit –∞–ø–ø-–∏–π–Ω “Ø–Ω–¥—Å—ç–Ω —Ç–æ—Ö–∏—Ä–≥–æ–æ
st.set_page_config(page_title="Twitter Sentiment Classifier", layout="wide")

# ”®–≥”©–≥–¥–ª–∏–π–≥ —Ü—ç–≤—ç—Ä–ª—ç—Ö —Ñ—É–Ω–∫—Ü
def clean_tweet(text):
    text = str(text).lower()                                # –¢–µ–∫—Å—Ç–∏–π–≥ –∂–∏–∂–∏–≥ “Ø—Å—ç–≥ –±–æ–ª–≥–æ—Ö
    text = re.sub(r"http\S+|www\.\S+", "", text)            # URL —É—Å—Ç–≥–∞—Ö
    text = re.sub(r"@\w+", "", text)                        # @username —É—Å—Ç–≥–∞—Ö
    text = re.sub(r"&amp;", "and", text)                    # &amp ‚Üí and –±–æ–ª–≥–æ—Ö
    text = re.sub(r"rt[\s]+", "", text)                     # RT (retweet) —É—Å—Ç–≥–∞—Ö
    text = re.sub(r"[^a-z0-9\s]", " ", text)                # –¢—ç–º–¥—ç–≥—Ç“Ø“Ø–¥–∏–π–≥ –∑–∞–π –±–æ–ª–≥–æ—Ö
    text = re.sub(r"\s+", " ", text).strip()                # –ù—ç–º—ç–ª—Ç –∑–∞–π —Ü—ç–≤—ç—Ä–ª—ç—Ö
    return text                                              # –¶—ç–≤—ç—Ä–ª—ç—Å—ç–Ω —Ç–µ–∫—Å—Ç –±—É—Ü–∞–∞—Ö

# CSV —Ñ–∞–π–ª–∞–∞—Å —É–Ω—à–∏—Ö 
def load_csv(uploaded_file):
    try:
        df = pd.read_csv(
            uploaded_file,
            encoding="latin-1",                              # Twitter dataset –ª–∞—Ç–∏–Ω –∫–æ–¥–ª–æ–≥–¥–¥–æ–≥
            header=None,                                     # –• –±–∞–≥–∞–Ω—É—É–¥–≥“Ø–π —Ç—É–ª –Ω—ç—Ä ”©–≥–Ω”©
            names=["target","id","date","flag","user","text"],  # –ë–∞–≥–∞–Ω—É—É–¥—ã–Ω –Ω—ç—Ä
            quoting=1, quotechar='"', escapechar="\\",      # –¢—ç–º–¥—ç–≥—Ç“Ø“Ø–¥–∏–π–≥ –∑”©–≤ —Ç–∞–π–ª–∞—Ö
            engine="python", on_bad_lines="skip"            # –ê–ª–¥–∞–∞—Ç–∞–π –º”©—Ä“Ø“Ø–¥–∏–π–≥ –∞–ª–≥–∞—Å–∞—Ö
        )
        return df
    except Exception as e:
        st.error(f"CSV —É–Ω—à–∏—Ö–∞–¥ –∞–ª–¥–∞–∞: {e}")                  # –•—ç—Ä—ç–≤ –∞–ª–¥–∞–∞ –≥–∞—Ä–≤–∞–ª Streamlit-–¥ —Ö–∞—Ä—É—É–ª–Ω–∞
        return None

# –¢–µ–∫—Å—Ç–∏–π–Ω —É—Ç–≥—ã–≥ —Ü—ç–≤—ç—Ä–ª—ç—Ö —Ñ—É–Ω–∫—Ü
def prepare_df(df):
    if "target" not in df.columns or "text" not in df.columns:
        st.error("CSV –Ω—å Twitter dataset —Ö—ç–ª–±—ç—Ä—Ç—ç–π –±–∞–π—Ö —ë—Å—Ç–æ–π.")   # –ê–ª–¥–∞–∞—Ç–∞–π —Ñ–∞–π–ª —à–∞–ª–≥–∞—Ö
        return None
    if set(df["target"].unique()) == {0,4}:                        # 0=negative, 4=positive
        df["target"] = df["target"].map({0:0, 4:1})                # “Ø–Ω—ç–Ω —Ö—É–¥–∞–ª –≥—ç—Å—ç–Ω —É—Ç–≥—É—É–¥—ã–≥ 4 ‚Üí 1 0 -> 0 –±–æ–ª–≥–æ–Ω map —Ö–∏–π—Ö
    df["clean_text"] = df["text"].astype(str).apply(clean_tweet)  # –¢–µ–∫—Å—Ç–∏–π–≥ —Ü—ç–≤—ç—Ä–ª—ç–∂ —à–∏–Ω—ç –±–∞–≥–∞–Ω–∞–¥ —Ö–∏–π—Ö
    return df

# Pipeline-–¥ –¥–∞—Ä–∞–∞–ª—Å–∞–Ω –∞–ª—Ö–∞–º—É—É–¥—ã–≥ –Ω—ç–≥—Ç–≥—ç—Ö (Tweet ‚Üí Vectorizer ‚Üí Classifier)
def build_pipelines():
    nb = Pipeline([
        ("vect", CountVectorizer(max_features=15000, ngram_range=(1,2))),  # 1, 2 “Ø–≥—Ç—ç–π unigram “Ø“Ø—Å–≥—ç–∂ —Ç—É—Ö–∞–π–Ω “Ø–≥–Ω–∏–π –¥–∞–≤—Ç–∞–º–∂–∏–π–≥ —Ç–æ–æ–ª–æ—Ö—ã–Ω —Ç—É–ª–¥ CountVectorizer –∞—à–∏–≥–ª–∞—Å–∞–Ω
        ("clf", MultinomialNB())                                           # Naive Bayes classifier
    ])
    lr = Pipeline([
        ("vect", TfidfVectorizer(max_features=20000, ngram_range=(1,2))),   # TF-IDF vectorization —Ç—É—Ö–∞–π–Ω unigram —É—Ç–≥—ã–Ω –∂–∏–Ω–≥ —Ç–æ–æ—Ü–æ—Ö —É—á—Ä–∞–∞—Å TfidVectorizer –∞—à–∏–≥–ª–∞—Å–∞–Ω
        ("clf", LogisticRegression(max_iter=1000, solver="liblinear"))       # Logistic Regression –∂–∏–∂–∏–≥ dataset-–¥ —Ç–æ—Ö–∏—Ä–æ–º–∂—Ç–æ–π —É—Ä–∞–∞—Å liblinear –∞—à–∏–≥–ª–∞—Å–∞–Ω
    ])
    return {"NaiveBayes": nb, "LogisticRegression": lr}                     # 2 –∑–∞–≥–≤–∞—Ä—ã–≥ dict –±–æ–ª–≥–æ–∂ –±—É—Ü–∞–∞—Ö


# “Æ–∑“Ø“Ø–ª—ç–ª—Ç“Ø“Ø–¥–∏–π–≥ —Ö—ç–≤–ª—ç—Ö —Ñ—É–Ω–∫—Ü
def evaluate(model, X_test, y_test):
    y_pred = model.predict(X_test)                   # –£—Ä—å–¥—á–∏–ª—Å–∞–Ω —Ç–∞–∞–º–∞–≥(vector classifier —Ä—É—É –¥–∞–º–∂—É—É–ª–Ω–∞)
    y_proba = model.predict_proba(X_test)[:,1]       # Positive class-–∏–π–Ω –º–∞–≥–∞–¥–ª–∞–ª
    return {
        "y_pred": y_pred,
        "y_proba": y_proba,
        "acc": accuracy_score(y_test, y_pred),       # Accuracy —Ç–æ–æ—Ü–æ—Ö
        "prec": precision_score(y_test, y_pred),     # Precision
        "rec": recall_score(y_test, y_pred),         # Recall
        "f1": f1_score(y_test, y_pred),              # F1 Score
        "auc": roc_auc_score(y_test, y_proba),       # AUC
        "cm": confusion_matrix(y_test, y_pred),      # Confusion matrix
        "report": classification_report(y_test, y_pred, digits=4)  # –î—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —Ç–∞–π–ª–±–∞—Ä
    }


# Streamlit UI —ç—Ö–ª“Ø“Ø–ª—ç—Ö
st.title("üìä Twitter Sentiment Classifier Dashboard")  
st.markdown("Upload CSV ‚Üí Train ‚Üí Compare models ‚Üí Posterior + Prediction + Correctness + Metrics")

uploaded_file = st.file_uploader("Upload CSV", type=["csv"])    # CSV upload control
test_size = st.slider("Test size (%)", 10, 50, 30)              # –¢–µ—Å—Ç–∏–π–Ω —Ö—É–≤–∏–π–≥ —Å–æ–Ω–≥–æ—Ö

if uploaded_file:
    df_raw = load_csv(uploaded_file)                             # CSV —Ñ–∞–π–ª—ã–≥ —É–Ω—à–∏—Ö
    if df_raw is not None:
        st.subheader("CSV Preview")
        st.write(df_raw.head())                                  # –≠—Ö–Ω–∏–π 5 –º”©—Ä–∏–π–≥ –±—É—é—É tweet-–∏–π–≥ —Ö–∞—Ä—É—É–ª–Ω–∞ 

        df = prepare_df(df_raw)                                  # –¢–µ–∫—Å—Ç–∏–π–≥ —Ü—ç–≤—ç—Ä–ª—ç–Ω—ç
        if df is not None:
            st.subheader("Dataset Summary")
            st.write(df["target"].value_counts())                # Positive / Negative —Ç–æ–æ

            X = df["clean_text"]                                 # Feature (—Ç–µ–∫—Å—Ç)
            y = df["target"]                                     # Label (0/1)
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size/100, stratify=y, random_state=42
            )

            st.subheader("Training Models...")
            models = build_pipelines()                           # 2 ML model
            results = {}                                         # “Æ—Ä –¥“Ø–Ω —Ö–∞–¥–≥–∞–ª–∞—Ö dict
            bar = st.progress(0)                                 # Progress bar

            # –ó–∞–≥–≤–∞—Ä—É—É–¥—ã–≥ —Å—É—Ä–≥–∞–∂, “Ø–Ω—ç–ª–≥—ç—ç –∞–≤–∞—Ö
            for i, (name, model) in enumerate(models.items(), start=1):
                model.fit(X_train, y_train)                      # –ó–∞–≥–≤–∞—Ä—ã–≥ —Å—É—Ä–≥–∞—Ö –∞–ª–≥–æ—Ä–∏—Ç–º —Ö—ç—Ä—ç–≥–∂“Ø“Ø–ª—ç–ª—Ç
                results[name] = evaluate(model, X_test, y_test)  # “Æ–Ω—ç–ª–≥—ç—ç —Ö–∏–π—Ö
                bar.progress(int(i/len(models)*100))             # –ü—Ä–æ–≥—Ä–µ—Å—Å %

            st.success("Training Done!")  # –ó–∞–≥–≤–∞—Ä —Å—É—Ä–≥–∞–ª—Ç –±“Ø—Ä—ç–Ω –¥—É—É—Å—Å–∞–Ω—ã–≥ Streamlit –¥—ç—ç—Ä –Ω–æ–≥–æ–æ–Ω –Ω–æ—Ç–æ–ª–≥–æ–æ–≥–æ–æ—Ä —Ö–∞—Ä—É—É–ª–Ω–∞.


            # –°—É—Ä–≥–∞—Å–∞–Ω –∑–∞–≥–≤–∞—Ä—É—É–¥—ã–Ω “Ø—Ä –¥“Ø–Ω–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
            st.subheader("üìå Model Metrics Overview")  #–•–æ—ë—Ä –∞–Ω–≥–∏–ª–∞–≥—á–∏–π–Ω (NB, LR) –≥–æ–ª “Ø–∑“Ø“Ø–ª—ç–ª—Ç“Ø“Ø–¥–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö –≥–∞—Ä—á–∏–≥
            for name, r in results.items():            #results dict –¥–æ—Ç–æ—Ä—Ö –±“Ø—Ö –º–æ–¥–µ–ª–∏—É–¥—ã–Ω –Ω—ç—Ä (name) –±–æ–ª–æ–Ω “Ø—Ä –¥“Ø–Ω (r)-–≥ –¥–∞–≤—Ç–∞–ª—Ç–∞–∞—Ä –∞–≤–∞—Ö
                st.markdown(f"### {name}", unsafe_allow_html=True)   # –ó–∞–≥–≤–∞—Ä—ã–Ω –Ω—ç—Ä–∏–π–≥ —Ç–æ–º –≥–∞—Ä—á–∏–≥ –±–æ–ª–≥–æ–Ω —Ö—ç–≤–ª—ç—Ö

                # 4 “Ø–∑“Ø“Ø–ª—ç–ª—Ç“Ø“Ø–¥–∏–π–≥ –±–∞–≥–∞–Ω–∞ –±–æ–ª–≥–æ–∂ —Ö–∞—Ä—É—É–ª–∞—Ö
                col1, col2, col3, col4 = st.columns(4)  # 4 –±–∞–≥–∞–Ω–∞ –±“Ø—Ö–∏–π layout “Ø“Ø—Å–≥—ç—Ö (Accuracy, Precision, Recall, F1-–≥ —Ö–∞–∂—É—É–¥–∞–∞ —Ö–∞—Ä–∞–≥–¥—É—É–ª–Ω–∞)
                col1.metric("Accuracy", f"{r['acc'] * 100:.2f}%")   # Accuracy-–≥ —Ö—É–≤—å –±–æ–ª–≥–æ–Ω —Ö–∞—Ä—É—É–ª–∞—Ö
                col2.metric("Precision", f"{r['prec'] * 100:.2f}%") # Precision —Ö—É–≤—å
                col3.metric("Recall", f"{r['rec'] * 100:.2f}%")     # Recall —Ö—É–≤—å
                col4.metric("F1 Score", f"{r['f1'] * 100:.2f}%")     # F1-score —Ö—É–≤—å



            # Posterior –º–∞–≥–∞–¥–ª–∞–ª, prediction, correctness-–≥ —Ö–∞—Ä—É—É–ª–∞—Ö —Ö—ç—Å—ç–≥
            st.subheader("Posterior Probability Table (First 10 Tweets)")  # –≠—Ö–Ω–∏–π 10 ”©–≥”©–≥–¥–ª–∏–π–Ω posterior –º–∞–≥–∞–¥–ª–∞–ª—ã–≥ —Ö“Ø—Å–Ω—ç–≥—Ç—ç—ç—Ä —Ö–∞—Ä—É—É–ª–Ω–∞
            posterior_table = pd.DataFrame({"Tweet": X_test[:10], "True Label": y_test[:10]})  
            # Test –¥–∞—Ç–∞–∞–≥–∞–∞—Å —ç—Ö–Ω–∏–π 10 –±–∏—á–ª—ç–≥–∏–π–≥ Tweet –±–æ–ª–æ–Ω –∂–∏–Ω—Ö—ç–Ω—ç Label —Ö—ç–ª–±—ç—Ä—ç—ç—Ä –∞–≤—á DataFrame “Ø“Ø—Å–≥—ç–Ω—ç

            # Posterior value, Prediction value, Correct —ç—Å—ç—Ö–∏–π–≥ –Ω—ç–º—ç—Ö
            for name, r in results.items():    # –•–æ—ë—Ä –º–æ–¥–µ–ª–∏—É–¥—ã–Ω “Ø—Ä –¥“Ø–Ω–≥ –¥–∞–≤—Ç–∞–ª—Ç–∞–∞—Ä –∞–≤–∞—Ö
                posterior_table[name+"_Posterior"] = r["y_proba"][:10]   # Posterior –º–∞–≥–∞–¥–ª–∞–ª—ã–Ω —ç—Ö–Ω–∏–π 10 –±–∏—á–ª—ç–≥–∏–π–≥ –Ω—ç–º—ç—Ö
                posterior_table[name+"_Prediction"] = r["y_pred"][:10]   # –£—Ä—å–¥—á–∏–ª—Å–∞–Ω –∞–Ω–≥–∏–ª–∞–ª (0 —ç—Å–≤—ç–ª 1)
                posterior_table[name+"_Correct?"] = r["y_pred"][:10] == y_test[:10]  # –ó”©–≤ —Ç–∞–∞—Å–∞–Ω —ç—Å—ç—Ö–∏–π–≥ Boolean (True/False —Ö—ç–ª–±—ç—Ä—ç—ç—Ä) –Ω—ç–º–Ω—ç

            st.dataframe(posterior_table, height=400)  # –ë—ç–ª—ç–Ω –±–æ–ª—Å–æ–Ω —Ö“Ø—Å–Ω—ç–≥—Ç–∏–π–≥ Streamlit-–¥ —Ö–∞—Ä—É—É–ª–∞—Ö

            
            
            #–°–æ–Ω–≥–æ—Å–æ–Ω –∏–Ω–¥–µ–∫—Å –¥—ç—ç—Ä—Ö “Ø–∑“Ø“Ø–ª—ç–ª—Ç“Ø“Ø–¥–∏–π–≥ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ –±–∞–π–¥–ª–∞–∞—Ä —Ö–∞—Ä—É—É–ª–∞—Ö —Ö—ç—Å—ç–≥
            st.subheader("üîé Interactive Posterior + Prediction")  #–°–æ–Ω–≥–æ—Å–æ–Ω Tweet-–∏–π–Ω posterior-–≥ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ —Ö–∞—Ä–∞—Ö UI –≥–∞—Ä—á–∏–≥
            idx = st.slider("Select Tweet Index", 0, len(X_test)-1, 0)  
            # –•—ç—Ä—ç–≥–ª—ç–≥—á test ”©–≥”©–≥–¥–ª–∏–π–Ω –∏–Ω–¥–µ–∫—Å–∏–π–≥ —Å–æ–Ω–≥–æ—Ö —Å–ª–∞–π–¥–µ—Ä (0-—Å —ç—Ö–ª—ç—ç–¥ —Ö–∞–º–≥–∏–π–Ω —Å“Ø“Ø–ª–∏–π–Ω Tweet —Ö“Ø—Ä—Ç—ç–ª)

            st.write("Tweet:", X_test.iloc[idx])              #–°–æ–Ω–≥–æ—Å–æ–Ω –∏–Ω–¥–µ–∫—Å–∏–π–Ω Tweet-–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
            st.write("Require True Label:", y_test.iloc[idx]) #–ó”©–≤ —Ö–∞—Ä–∏—É–≥ —Ö–∞—Ä—É—É–ª–∞—Ö

            # –•–æ—ë—Ä –∑–∞–≥–≤–∞—Ä—ã–Ω posterior-–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
            for name, r in results.items():               # –ú–æ–¥–µ–ª–∏—É–¥—ã–≥ –¥–∞–≤—Ç–∞–ª—Ç–∞–∞—Ä —à–∞–ª–≥–∞—Ö
                posterior = r["y_proba"][idx]            # –°–æ–Ω–≥–æ—Å–æ–Ω –∏–Ω–¥–µ–∫—Å–∏–π–Ω posterior probability
                pred = r["y_pred"][idx]                  # –°–æ–Ω–≥–æ—Å–æ–Ω –∏–Ω–¥–µ–∫—Å–∏–π–Ω prediction (0/1)
                correct = "‚úÖ True" if pred == y_test.iloc[idx] else "‚ùå False"  
                # Prediction –∑”©–≤ —ç—Å—ç—Ö–∏–π–≥ —Ç—ç–º–¥—ç–≥–ª—ç–≥—ç—ç—Ç—ç–π —Ö–∞—Ä—É—É–ª–Ω–∞

                st.metric(label=f"{name} Posterior (+ probability)", value=f"{posterior * 100:.2f}%")  
                # Posterior probability-–≥ —Ö—É–≤—å —Ö—ç–ª–±—ç—Ä—ç—ç—Ä —Ö–∞—Ä—É—É–ª–∞—Ö
                st.write(f"{name} Prediction:", pred, "| Correct?", correct)  
                # Prediction –±–æ–ª–æ–Ω –∑”©–≤ —ç—Å—ç—Ö


            # Confusion Matrix
            st.subheader("üîé Confusion Matrix (T/F row & column labels)")  
            # –ó–∞–≥–≤–∞—Ä —Ç—É—Å –±“Ø—Ä–∏–π–Ω —Ö“Ø—Ä—ç—ç –º–∞—Ç—Ä–∏—Ü (Confusion Matrix)‚Äì–≥ —Ö–∞—Ä—É—É–ª–∞—Ö

            cols = st.columns(len(results))  # –ú–æ–¥–µ–ª–∏—É–¥—ã–Ω —Ç–æ–æ—Ç–æ–π —Ç—ç–Ω—Ü“Ø“Ø —Ö—ç–º–∂—ç—ç—Ç—ç–π –±–∞–≥–∞–Ω—ã–≥ UI-–¥ “Ø“Ø—Å–≥—ç–Ω—ç (2 model ‚Üí 2 column)

            for col, (name, r) in zip(cols, results.items()):  # –ë–∞–≥–∞–Ω–∞ –±“Ø—Ä—Ç –Ω—ç–≥ –∑–∞–≥–≤–∞—Ä –±–∞–π—Ä–ª—É—É–ª–Ω–∞
                with col:
                    st.markdown(f"### {name}")  # –ó–∞–≥–≤–∞—Ä—ã–Ω –Ω—ç—Ä

                    cm_vals = r["cm"]           # Confusion matrix —É—Ç–≥—É—É–¥—ã–≥ –∞–≤–Ω–∞

                    fig, ax = plt.subplots(figsize=(5, 4))  #Heatmap –∑—É—Ä–∞—Ö —à–∏–Ω—ç Figure “Ø“Ø—Å–≥—ç–Ω—ç
                    sns.heatmap(
                        cm_vals,                # Confusion matrix-–∏–π–Ω —Ç–æ–æ–Ω ”©–≥”©–≥–¥”©–ª
                        annot=True,             # –¢–æ–æ–Ω—É—É–¥—ã–≥ –¥–æ—Ç—Ä–æ–æ —Ö–∞—Ä—É—É–ª–Ω–∞
                        fmt="d",                # –¢–æ–æ–Ω—É—É–¥—ã–≥ integer —Ö—ç–ª–±—ç—Ä—ç—ç—Ä —Ö–∞—Ä—É—É–ª–∞—Ö
                        cmap="YlGnBu",          # ”®–Ω–≥”©–Ω–∏–π —Å—Ö–µ–º
                        ax=ax,                  # –•–∞–∞–Ω–∞ –∑—É—Ä–∞—Ö—ã–≥ –∑–∞–∞–∂ ”©–≥—á –±–∞–π–Ω–∞
                        annot_kws={"size":12, "weight":"bold"}, # —Ñ–æ–Ω—Ç—ã–Ω –∑–∞–≥–≤–∞—Ä
                        linewidths=1,           # —à—É–≥–∞–º—ã–Ω ”©—Ä–≥”©–Ω
                        linecolor="white",      # —à—É–≥–∞–º—ã–Ω ”©–Ω–≥”©
                        cbar=True               # Color bar —Ö–∞—Ä—É—É–ª–∞—Ö —ç—Å—ç—Ö
                    )

                    ax.set_yticklabels(['T','F'], rotation=0)  # Y —Ç—ç–Ω—Ö–ª—ç–≥–∏–π–Ω (Actual) —Ç—ç–º–¥—ç–≥–ª—ç–≥—ç—ç: T=True, F=False
                    ax.set_xticklabels(['F','T'], rotation=0)  # X —Ç—ç–Ω—Ö–ª—ç–≥–∏–π–Ω (Predicted) —Ç—ç–º–¥—ç–≥–ª—ç–≥—ç—ç

                    ax.set_xlabel("Predicted")                 # X —Ç—ç–Ω—Ö–ª—ç–≥–∏–π–Ω –Ω—ç—Ä
                    ax.set_ylabel("Actual")                   # Y —Ç—ç–Ω—Ö–ª—ç–≥–∏–π–Ω –Ω—ç—Ä
                    ax.set_title(f"{name} Confusion Matrix (T/F)")  # –ì—Ä–∞—Ñ–∏–∫–∏–π–Ω –≥–∞—Ä—á–∏–≥

                    st.pyplot(fig, use_container_width=True)  # Streamlit-–¥ –≥—Ä–∞—Ñ–∏–∫–∏–π–≥ —Ö—ç–≤–ª—ç—Ö


            # 3D Posterior Histogram
            st.subheader("üîéPosterior Probability Distribution (3D View)")  
            # Posterior –º–∞–≥–∞–¥–ª–∞–ª—ã–Ω —Ç–∞—Ä—Ö–∞–ª—Ç—ã–≥ 3D –±–∞–≥–∞–Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∞–∞—Ä —Ö–∞—Ä—É—É–ª–∞—Ö (–∑–∞–≥–≤–∞—Ä —Ç—É—Å –±“Ø—Ä—Ç)

            cols = st.columns(len(results))  # –ú–æ–¥–µ–ª–∏—É–¥—ã–Ω —Ç–æ–æ—Ç–æ–π —Ç—ç–Ω—Ü—ç—Ö –±–∞–≥–∞–Ω–∞

            for col, (name, r) in zip(cols, results.items()):
                with col:
                    fig = plt.figure(figsize=(5,4))                 # –®–∏–Ω—ç Figure “Ø“Ø—Å–≥—ç–Ω—ç
                    ax = fig.add_subplot(111, projection='3d')      # 3D subplot “Ø“Ø—Å–≥—ç–Ω—ç

                    hist, bins = np.histogram(r["y_proba"], bins=25)  # Posterior probability-–≥ histogram –±–æ–ª–≥–æ—Ö
                    xpos = (bins[:-1] + bins[1:]) / 2                # –ë–∞–≥–∞–Ω—É—É–¥—ã–Ω X –±–∞–π—Ä–ª–∞–ª
                    ypos = np.zeros_like(xpos)                       # Y –±–∞–π—Ä–ª–∞–ª –±“Ø–≥–¥ 0 (3D –±–∞—Ä-–Ω–¥ dummy)
                    zpos = np.zeros_like(xpos)                       # –ë–∞–≥–∞–Ω–∞ Z —ç—Ö–ª—ç–ª 0
                    dx = (bins[1]-bins[0]) * np.ones_like(xpos)      # –ë–∞–≥–∞–Ω—É—É–¥—ã–Ω ”©—Ä–≥”©–Ω (X)
                    dy = np.ones_like(xpos)                          # Y –∑—É–∑–∞–∞–Ω
                    dz = hist                                        # –ë–∞–≥–∞–Ω—É—É–¥—ã–Ω ”©–Ω–¥”©—Ä

                    colors = cm.viridis(dz / dz.max())               # Histogram ”©–Ω–¥”©—Ä—Ç —Å—É—É—Ä–∏–ª—Å–∞–Ω ”©–Ω–≥”©

                    ax.bar3d(xpos, ypos, zpos, dx, dy, dz, color=colors, edgecolor='k')  
                    # 3D –±–∞—Ä –≥—Ä–∞—Ñ–∏–∫ –∑—É—Ä–∞—Ö —Ö—ç—Å—ç–≥

                    ax.set_xlabel('Posterior Probability')  # X —Ç—ç–Ω—Ö–ª—ç–≥–∏–π–Ω –Ω—ç—Ä
                    ax.set_ylabel('Y (dummy)')              # Dummy Y —Ç—ç–Ω—Ö–ª—ç–≥
                    ax.set_zlabel('Frequency')              # Frequency –±—É—é—É –¥–∞–≤—Ç–∞–º–∂
                    ax.set_title(f"{name} Posterior Probability (3D)")  # –ì–∞—Ä—á–∏–≥

                    ax.view_init(elev=30, azim=-60)  # —Ö–∞—Ä–∞—Ö ”©–Ω—Ü”©–≥ —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö

                    st.pyplot(fig, use_container_width=True)  # Streamlit-–¥ —Ö—ç–≤–ª—ç—Ö



            # Tweet –±“Ø—Ä–∏–π–Ω —Ö—É–≤—å–¥ NB –±–∞ LR –∑–∞–≥–≤–∞—Ä—ã–Ω –≥–∞—Ä–≥–∞—Å–∞–Ω posterior probability-–≥ —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ –≥—Ä–∞—Ñ–∏–∫
            st.subheader("Interactive Scatter Plots: Posterior Comparison & Correctness")  
            # NB –±–∞ LR —Ö–æ—ë—Ä—ã–Ω posterior-–≥ —Ö–æ–æ—Ä–æ–Ω–¥ –Ω—å —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤ Plotly –≥—Ä–∞—Ñ–∏–∫

            df_scatter = pd.DataFrame({
                "NB_Proba": results["NaiveBayes"]["y_proba"],            # NB posterior probability
                "LR_Proba": results["LogisticRegression"]["y_proba"],    # LR posterior probability
                "True_Label": y_test.values,                             # –ñ–∏–Ω—Ö—ç–Ω—ç Label
                "Tweet": X_test.values,                                  # Tweet —Ç–µ–∫—Å—Ç
                "NB_Correct": results["NaiveBayes"]["y_pred"] == y_test, # NB –∑”©–≤ —Ç–∞–∞—Å–∞–Ω —ç—Å—ç—Ö
                "LR_Correct": results["LogisticRegression"]["y_pred"] == y_test # LR –∑”©–≤ —Ç–∞–∞—Å–∞–Ω —ç—Å—ç—Ö
            })

            cols = st.columns(2)  #2 –≥—Ä–∞—Ñ–∏–∫–∏–π–≥ –∑—ç—Ä—ç–≥—Ü“Ø“Ø–ª—ç–Ω —Ö–∞—Ä–∞–≥–¥—É—É–ª–∞—Ö —Ö–æ—ë—Ä –±–∞–≥–∞–Ω–∞

            # Posterior comparison chart
            with cols[0]:
                fig1 = px.scatter(
                    df_scatter,
                    x="NB_Proba",     # NB posterior probability X —Ç—ç–Ω—Ö–ª—ç–≥
                    y="LR_Proba",     # LR posterior probability Y —Ç—ç–Ω—Ö–ª—ç–≥
                    color="True_Label",   # –ñ–∏–Ω—Ö—ç–Ω—ç Label-–∏–π–≥ ”©–Ω–≥”©”©—Ä —è–ª–≥–∞–Ω–∞
                    hover_data={"Tweet": True},   # Mouse-–≥ tweet –¥—ç—ç—Ä –∞–≤—á—Ä–∞—Ö–∞–¥ —Ö–∞—Ä—É—É–ª–∞—Ö —Ç–µ–∫—Å—Ç
                    title="Posterior Probability Comparison"  # –ì–∞—Ä—á–∏–≥
                )
                st.plotly_chart(fig1, use_container_width=True)  # Streamlit-–¥ —Ö—ç–≤–ª—ç—Ö

            # NB –±–∞ LR-–∏–π–Ω –∑”©–≤ —Ç–∞–∞—Å–∞–Ω —ç—Å—ç—Ö—Ç—ç–π —Ö–∞—Ä—å—Ü—É—É–ª–∞–Ω —Ö–∞—Ä—É—É–ª–∞—Ö –≥—Ä–∞—Ñ–∏–∫
            with cols[1]:
                df_scatter["Both_Correct"] = df_scatter["NB_Correct"] & df_scatter["LR_Correct"]  
                # –•–æ—ë—Ä –∑–∞–≥–≤–∞—Ä —Ö–æ—ë—É–ª–∞–∞ –∑”©–≤ –±–∞–π—Å–∞–Ω —ç—Å—ç—Ö–∏–π–≥ —Ç–æ–æ—Ü–æ—Ö

                fig2 = px.scatter(
                    df_scatter,
                    x="NB_Proba",         # NB posterior
                    y="LR_Proba",         # LR posterior
                    color="Both_Correct", # –•—ç—Ä–≤—ç—ç NB –±–æ–ª–æ–Ω LR —Ö–æ—ë—É–ª–∞–∞ –∑”©–≤ ‚Üí True, “Ø–≥“Ø–π –±–æ–ª False
                    hover_data={"Tweet": True},  # Tweet —Ç–µ–∫—Å—Ç —Ö–∞—Ä—É—É–ª–∞—Ö
                    title="Correct vs Incorrect Predictions"  # –ì—Ä–∞—Ñ–∏–∫–∏–π–Ω –Ω—ç—Ä
                )
                st.plotly_chart(fig2, use_container_width=True)  # Streamlit-–¥ –≥—Ä–∞—Ñ–∏–∫–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö

        else:
                st.info("‚è≥ Upload CSV to train and see posterior probability, prediction, correctness, and metrics.")  
                # –•—ç—Ä–≤—ç—ç CSV upload —Ö–∏–π–≥–¥—ç—ç–≥“Ø–π –±–æ–ª –º—ç–¥—ç—ç–ª–ª–∏–π–Ω –º–µ—Å—Å–µ–∂ —Ö–∞—Ä—É—É–ª–∞—Ö
